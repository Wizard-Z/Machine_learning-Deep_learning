{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN - Character Level Model for name generation.\n",
    "Based on Coursera Course on Sequence Models.\n",
    "- Using Recurrent Neural Networks it generates random names.\n",
    "- Network is trained on Baby names.\n",
    "Different names of babies born in the year 2017.\n",
    "- Training done on Google's Colab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7tVh3CB0fJsn",
    "outputId": "01518464-7393-4c32-f2d3-c32bc2a48a93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive  sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gECfzB1wb2B5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#from utils import *\n",
    "import random\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i_keNY5-fiQQ"
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)\n",
    "\n",
    "def smooth(loss, cur_loss):\n",
    "    return loss * 0.999 + cur_loss * 0.001\n",
    "\n",
    "def print_sample(sample_ix, ix_to_char):\n",
    "    txt = ''.join(ix_to_char[ix] for ix in sample_ix)\n",
    "    txt = txt[0].upper() + txt[1:]  # capitalize first character \n",
    "    print ('%s' % (txt, ), end='')\n",
    "\n",
    "def get_initial_loss(vocab_size, seq_length):\n",
    "    return -np.log(1.0/vocab_size)*seq_length\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)\n",
    "\n",
    "def initialize_parameters(n_a, n_x, n_y):\n",
    "    \"\"\"\n",
    "    Initialize parameters with small random values\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing:\n",
    "                        Wax -- Weight matrix multiplying the input, numpy array of shape (n_a, n_x)\n",
    "                        Waa -- Weight matrix multiplying the hidden state, numpy array of shape (n_a, n_a)\n",
    "                        Wya -- Weight matrix relating the hidden-state to the output, numpy array of shape (n_y, n_a)\n",
    "                        b --  Bias, numpy array of shape (n_a, 1)\n",
    "                        by -- Bias relating the hidden-state to the output, numpy array of shape (n_y, 1)\n",
    "    \"\"\"\n",
    "    np.random.seed(1)\n",
    "    Wax = np.random.randn(n_a, n_x)*0.01 # input to hidden\n",
    "    Waa = np.random.randn(n_a, n_a)*0.01 # hidden to hidden\n",
    "    Wya = np.random.randn(n_y, n_a)*0.01 # hidden to output\n",
    "    b = np.zeros((n_a, 1)) # hidden bias\n",
    "    by = np.zeros((n_y, 1)) # output bias\n",
    "    \n",
    "    parameters = {\"Wax\": Wax, \"Waa\": Waa, \"Wya\": Wya, \"b\": b,\"by\": by}\n",
    "    \n",
    "    return parameters\n",
    "\n",
    "def rnn_step_forward(parameters, a_prev, x):\n",
    "    \n",
    "    Waa, Wax, Wya, by, b = parameters['Waa'], parameters['Wax'], parameters['Wya'], parameters['by'], parameters['b']\n",
    "    a_next = np.tanh(np.dot(Wax, x) + np.dot(Waa, a_prev) + b) # hidden state\n",
    "    p_t = softmax(np.dot(Wya, a_next) + by) # unnormalized log probabilities for next chars # probabilities for next chars \n",
    "    \n",
    "    return a_next, p_t\n",
    "\n",
    "def rnn_step_backward(dy, gradients, parameters, x, a, a_prev):\n",
    "    \n",
    "    gradients['dWya'] += np.dot(dy, a.T)\n",
    "    gradients['dby'] += dy\n",
    "    da = np.dot(parameters['Wya'].T, dy) + gradients['da_next'] # backprop into h\n",
    "    daraw = (1 - a * a) * da # backprop through tanh nonlinearity\n",
    "    gradients['db'] += daraw\n",
    "    gradients['dWax'] += np.dot(daraw, x.T)\n",
    "    gradients['dWaa'] += np.dot(daraw, a_prev.T)\n",
    "    gradients['da_next'] = np.dot(parameters['Waa'].T, daraw)\n",
    "    return gradients\n",
    "\n",
    "def update_parameters(parameters, gradients, lr):\n",
    "\n",
    "    parameters['Wax'] += -lr * gradients['dWax']\n",
    "    parameters['Waa'] += -lr * gradients['dWaa']\n",
    "    parameters['Wya'] += -lr * gradients['dWya']\n",
    "    parameters['b']  += -lr * gradients['db']\n",
    "    parameters['by']  += -lr * gradients['dby']\n",
    "    return parameters\n",
    "\n",
    "def rnn_forward(X, Y, a0, parameters, vocab_size = 27):\n",
    "    \n",
    "    # Initialize x, a and y_hat as empty dictionaries\n",
    "    x, a, y_hat = {}, {}, {}\n",
    "    \n",
    "    a[-1] = np.copy(a0)\n",
    "    \n",
    "    # initialize your loss to 0\n",
    "    loss = 0\n",
    "    \n",
    "    for t in range(len(X)):\n",
    "        \n",
    "        # Set x[t] to be the one-hot vector representation of the t'th character in X.\n",
    "        # if X[t] == None, we just have x[t]=0. This is used to set the input for the first timestep to the zero vector. \n",
    "        x[t] = np.zeros((vocab_size,1)) \n",
    "        if (X[t] != None):\n",
    "            x[t][X[t]] = 1\n",
    "        \n",
    "        # Run one step forward of the RNN\n",
    "        a[t], y_hat[t] = rnn_step_forward(parameters, a[t-1], x[t])\n",
    "        \n",
    "        # Update the loss by substracting the cross-entropy term of this time-step from it.\n",
    "        loss -= np.log(y_hat[t][Y[t],0])\n",
    "        \n",
    "    cache = (y_hat, a, x)\n",
    "        \n",
    "    return loss, cache\n",
    "\n",
    "def rnn_backward(X, Y, parameters, cache):\n",
    "    # Initialize gradients as an empty dictionary\n",
    "    gradients = {}\n",
    "    \n",
    "    # Retrieve from cache and parameters\n",
    "    (y_hat, a, x) = cache\n",
    "    Waa, Wax, Wya, by, b = parameters['Waa'], parameters['Wax'], parameters['Wya'], parameters['by'], parameters['b']\n",
    "    \n",
    "    # each one should be initialized to zeros of the same dimension as its corresponding parameter\n",
    "    gradients['dWax'], gradients['dWaa'], gradients['dWya'] = np.zeros_like(Wax), np.zeros_like(Waa), np.zeros_like(Wya)\n",
    "    gradients['db'], gradients['dby'] = np.zeros_like(b), np.zeros_like(by)\n",
    "    gradients['da_next'] = np.zeros_like(a[0])\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Backpropagate through time\n",
    "    for t in reversed(range(len(X))):\n",
    "        dy = np.copy(y_hat[t])\n",
    "        dy[Y[t]] -= 1\n",
    "        gradients = rnn_step_backward(dy, gradients, parameters, x[t], a[t], a[t-1])\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return gradients, a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y7x1cyk5b2B9"
   },
   "outputs": [],
   "source": [
    "names_list = pd.read_csv('drive/My Drive/Colab Notebooks/character level model/yob2017.txt',header=None)\n",
    "boy_names = names_list[names_list[1]=='M'][0].apply(str.lower)\n",
    "girl_names = names_list[names_list[1] == 'F'][0].apply(str.lower)\n",
    "combined = names_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rJgO9W-Mb2CJ"
   },
   "outputs": [],
   "source": [
    "def get_names_string(names_list):\n",
    "    '''\n",
    "    takes list like object and returns elements concatinated in string form.\n",
    "    '''\n",
    "    str_names = ''\n",
    "    for name in names_list:\n",
    "        str_names += name + '\\n'\n",
    "    return(str_names.lower())\n",
    "def get_chars_data_size_vocab_size(data):\n",
    "    '''\n",
    "    Takes a list like data and return \n",
    "    i.characters in it.\n",
    "    ii. string representation.\n",
    "    iii. data size\n",
    "    iv. vocab size\n",
    "    return (chars,names,data_size, vocab_size)\n",
    "    '''\n",
    "    names = get_names_string(data)\n",
    "    chars = list(set(names))\n",
    "    data_size, vocab_size = len(names), len(chars)\n",
    "    print('There are %d total characters and %d unique characters in your data.' % (data_size, vocab_size))\n",
    "    return (chars,names,data_size, vocab_size)\n",
    "\n",
    "\n",
    "def get_dicss(characters):\n",
    "    '''\n",
    "    Return dictionaries\n",
    "    Characters -> to Index\n",
    "    Index -> to Characters\n",
    "    return (ix_to_char,char_to_ix)\n",
    "    '''\n",
    "    char_to_ix = { ch:i for i,ch in enumerate(sorted(characters)) }\n",
    "    ix_to_char = { i:ch for i,ch in enumerate(sorted(characters)) }\n",
    "    print('Printing Index to Characters\\n',ix_to_char)\n",
    "    return (ix_to_char,char_to_ix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clipping gradients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lz6LyRzpb2CQ"
   },
   "outputs": [],
   "source": [
    "def clip(gradients, maxValue):\n",
    "    '''\n",
    "    Clips the gradients' values between minimum and maximum.\n",
    "    \n",
    "    Arguments:\n",
    "    gradients -- a dictionary containing the gradients \"dWaa\", \"dWax\", \"dWya\", \"db\", \"dby\"\n",
    "    maxValue -- everything above this number is set to this number, and everything less than -maxValue is set to -maxValue\n",
    "    \n",
    "    Returns: \n",
    "    gradients -- a dictionary with the clipped gradients.\n",
    "    '''\n",
    "    \n",
    "    dWaa, dWax, dWya, db, dby = gradients['dWaa'], gradients['dWax'], gradients['dWya'], gradients['db'], gradients['dby']\n",
    "   \n",
    "    # clip to mitigate exploding gradients, loop over [dWax, dWaa, dWya, db, dby]. (≈2 lines)\n",
    "    for gradient in [dWax, dWaa, dWya, db, dby]:\n",
    "        \n",
    "        np.clip(gradient, -maxValue, maxValue, gradient)\n",
    "\n",
    "    \n",
    "    gradients = {\"dWaa\": dWaa, \"dWax\": dWax, \"dWya\": dWya, \"db\": db, \"dby\": dby}\n",
    "    \n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KXITq9C0b2CU"
   },
   "outputs": [],
   "source": [
    "def sample(parameters, char_to_ix, seed):\n",
    "    \"\"\"\n",
    "    Sample a sequence of characters according to a sequence of probability distributions output of the RNN\n",
    "\n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing the parameters Waa, Wax, Wya, by, and b. \n",
    "    char_to_ix -- python dictionary mapping each character to an index.\n",
    "    seed -- used for grading purposes. Do not worry about it.\n",
    "\n",
    "    Returns:\n",
    "    indices -- a list of length n containing the indices of the sampled characters.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve parameters and relevant shapes from \"parameters\" dictionary\n",
    "    Waa, Wax, Wya, by, b = parameters['Waa'], parameters['Wax'], parameters['Wya'], parameters['by'], parameters['b']\n",
    "    vocab_size = by.shape[0]\n",
    "    n_a = Waa.shape[1]\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Step 1: Create the one-hot vector x for the first character (initializing the sequence generation). (≈1 line)\n",
    "    x = np.zeros((vocab_size, 1))\n",
    "    # Step 1': Initialize a_prev as zeros (≈1 line)\n",
    "    a_prev = np.zeros((n_a,1))\n",
    "    \n",
    "    # Create an empty list of indices, this is the list which will contain the list of indices of the characters to generate (≈1 line)\n",
    "    indices = []\n",
    "    \n",
    "    # Idx is a flag to detect a newline character, we initialize it to -1\n",
    "    idx = -1 \n",
    "    \n",
    "    # Loop over time-steps t. At each time-step, sample a character from a probability distribution and append \n",
    "    # its index to \"indices\". We'll stop if we reach 50 characters (which should be very unlikely with a well \n",
    "    # trained model), which helps debugging and prevents entering an infinite loop. \n",
    "    counter = 0\n",
    "    newline_character = char_to_ix['\\n']\n",
    "    \n",
    "    while (idx != newline_character and counter != 50):\n",
    "        \n",
    "        # Step 2: Forward propagate x using the equations (1), (2) and (3)\n",
    "        a = np.tanh(np.dot(Wax,x) + np.dot(Waa, a_prev) + b)\n",
    "        z = np.dot(Wya,a) + by\n",
    "        y = softmax(z)\n",
    "        \n",
    "        # for grading purposes\n",
    "        np.random.seed(counter+seed) \n",
    "        \n",
    "        # Step 3: Sample the index of a character within the vocabulary from the probability distribution y\n",
    "        idx = np.random.choice(list(range(vocab_size)), p=y.ravel())\n",
    "\n",
    "        # Append the index to \"indices\"\n",
    "        indices.append(idx)\n",
    "        \n",
    "        # Step 4: Overwrite the input character as the one corresponding to the sampled index.\n",
    "        x = np.zeros((vocab_size,1))\n",
    "        x[idx] = 1\n",
    "        \n",
    "        # Update \"a_prev\" to be \"a\"\n",
    "        a_prev = a\n",
    "    \n",
    "        # for grading purposes\n",
    "        seed += 1\n",
    "        counter +=1\n",
    "        \n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    if (counter == 50):\n",
    "        indices.append(char_to_ix['\\n'])\n",
    "    \n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wzPEIYvQb2CZ"
   },
   "outputs": [],
   "source": [
    "def optimize(X, Y, a_prev, parameters, learning_rate = 0.01):\n",
    "    \"\"\"\n",
    "    Execute one step of the optimization to train the model.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- list of integers, where each integer is a number that maps to a character in the vocabulary.\n",
    "    Y -- list of integers, exactly the same as X but shifted one index to the left.\n",
    "    a_prev -- previous hidden state.\n",
    "    parameters -- python dictionary containing:\n",
    "                        Wax -- Weight matrix multiplying the input, numpy array of shape (n_a, n_x)\n",
    "                        Waa -- Weight matrix multiplying the hidden state, numpy array of shape (n_a, n_a)\n",
    "                        Wya -- Weight matrix relating the hidden-state to the output, numpy array of shape (n_y, n_a)\n",
    "                        b --  Bias, numpy array of shape (n_a, 1)\n",
    "                        by -- Bias relating the hidden-state to the output, numpy array of shape (n_y, 1)\n",
    "    learning_rate -- learning rate for the model.\n",
    "    \n",
    "    Returns:\n",
    "    loss -- value of the loss function (cross-entropy)\n",
    "    gradients -- python dictionary containing:\n",
    "                        dWax -- Gradients of input-to-hidden weights, of shape (n_a, n_x)\n",
    "                        dWaa -- Gradients of hidden-to-hidden weights, of shape (n_a, n_a)\n",
    "                        dWya -- Gradients of hidden-to-output weights, of shape (n_y, n_a)\n",
    "                        db -- Gradients of bias vector, of shape (n_a, 1)\n",
    "                        dby -- Gradients of output bias vector, of shape (n_y, 1)\n",
    "    a[len(X)-1] -- the last hidden state, of shape (n_a, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Forward propagate through time (≈1 line)\n",
    "    loss, cache = rnn_forward(X, Y, a_prev, parameters)\n",
    "    \n",
    "    # Backpropagate through time (≈1 line)\n",
    "    gradients, a = rnn_backward(X, Y, parameters, cache)\n",
    "    \n",
    "    # Clip your gradients between -5 (min) and 5 (max) (≈1 line)\n",
    "    gradients = clip(gradients, 5)\n",
    "    \n",
    "    # Update parameters (≈1 line)\n",
    "    parameters = update_parameters(parameters, gradients, learning_rate)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return loss, gradients, a[len(X)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j_hz9JuDb2Cd"
   },
   "outputs": [],
   "source": [
    "\n",
    "def model(data, ix_to_char, char_to_ix, num_iterations = 10000, n_a = 500, sample_no = 10, vocab_size = 27):\n",
    "    \"\"\"\n",
    "    Trains the model and generates dinosaur names. \n",
    "    \n",
    "    Arguments:\n",
    "    data -- text corpus\n",
    "    ix_to_char -- dictionary that maps the index to a character\n",
    "    char_to_ix -- dictionary that maps a character to an index\n",
    "    num_iterations -- number of iterations to train the model for\n",
    "    n_a -- number of units of the RNN cell\n",
    "    sample_no -- number of names you want to sample at each iteration. \n",
    "    vocab_size -- number of unique characters found in the text, size of the vocabulary\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- learned parameters\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve n_x and n_y from vocab_size\n",
    "    iter_loss = []\n",
    "    n_x, n_y = vocab_size, vocab_size\n",
    "    \n",
    "    # Initialize parameters\n",
    "    parameters = initialize_parameters(n_a, n_x, n_y)\n",
    "    \n",
    "    # Initialize loss (this is required because we want to smooth our loss, don't worry about it)\n",
    "    loss = get_initial_loss(vocab_size, sample_no)\n",
    "    \n",
    "    # Build list of all dinosaur names (training examples).\n",
    "\n",
    "    examples = data.split('\\n')\n",
    "    \n",
    "    # Shuffle list of all  names\n",
    "    np.random.seed(0)\n",
    "    np.random.shuffle(examples)\n",
    "    \n",
    "    # Initialize the hidden state of your LSTM\n",
    "    a_prev = np.zeros((n_a, 1))\n",
    "    \n",
    "    # Optimization loop\n",
    "    for j in range(num_iterations):     \n",
    "        # Use the hint above to define one training example (X,Y) (≈ 2 lines)\n",
    "        index = j % len(examples)\n",
    "        X = [None] + [char_to_ix[ch] for ch in examples[index]] \n",
    "        Y = X[1:] + [char_to_ix[\"\\n\"]]\n",
    "        # Perform one optimization step: Forward-prop -> Backward-prop -> Clip -> Update parameters\n",
    "        # Choose a learning rate of 0.01\n",
    "        curr_loss, gradients, a_prev = optimize(X, Y, a_prev, parameters, learning_rate = 0.01)\n",
    "        \n",
    "        # Use a latency trick to keep the loss smooth. It happens here to accelerate the training.\n",
    "        loss = smooth(loss, curr_loss)\n",
    "\n",
    "        # Every 2000 Iteration, generate \"n\" characters thanks to sample() to check if the model is learning properly\n",
    "        if j% 100 == 0:\n",
    "          iter_loss.append(loss)\n",
    "        if j % 2000 == 0:\n",
    "            print('Iteration: %d, Loss: %f' % (j, loss) + '\\n')\n",
    "            \n",
    "            # The number of names to print\n",
    "            seed = 0\n",
    "            for name in range(sample_no):\n",
    "                \n",
    "                # Sample indices and print them\n",
    "                sampled_indices = sample(parameters, char_to_ix, seed)\n",
    "                print_sample(sampled_indices, ix_to_char)\n",
    "                \n",
    "                seed += 1  # To get the same result for grading purposed, increment the seed by one. \n",
    "      \n",
    "            print('\\n')\n",
    "        \n",
    "    return (parameters,iter_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "id": "CVFsej47b2Cl",
    "outputId": "49a8884f-6fb1-495c-8cee-30fdf1bc852d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 98348 total characters and 27 unique characters in your data.\n",
      "Printing Index to Characters\n",
      " {0: '\\n', 1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z'}\n",
      "There are 133370 total characters and 27 unique characters in your data.\n",
      "Printing Index to Characters\n",
      " {0: '\\n', 1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z'}\n",
      "There are 231718 total characters and 27 unique characters in your data.\n",
      "Printing Index to Characters\n",
      " {0: '\\n', 1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z'}\n"
     ]
    }
   ],
   "source": [
    "# Boys_names\n",
    "chars, boy_strings,data_size,vocab_size= get_chars_data_size_vocab_size(boy_names)\n",
    "ix_to_char,char_to_ix = get_dicss(chars)\n",
    "# Girls_names\n",
    "chars, girl_strings,data_size,vocab_size= get_chars_data_size_vocab_size(girl_names)\n",
    "ix_to_char,char_to_ix = get_dicss(chars)\n",
    "# Combined\n",
    "chars, combined_strings,data_size,vocab_size= get_chars_data_size_vocab_size(combined)\n",
    "ix_to_char,char_to_ix = get_dicss(chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainig of different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 5967
    },
    "colab_type": "code",
    "id": "3L49gZZgb2Cs",
    "outputId": "6daa43b8-ba05-4257-e9ab-f3495531e729"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0, Loss: 32.951764\n",
      "\n",
      "Nkzxwtdmfqoeyhsqwasjjjvu\n",
      "Kneb\n",
      "Kzxwtdmfqoeyhsqwasjjjvu\n",
      "Neb\n",
      "Zxwtdmfqoeyhsqwasjjjvu\n",
      "Eb\n",
      "Xwtdmfqoeyhsqwasjjjvu\n",
      "B\n",
      "Wtdmfqoeyhsqwasjjjvu\n",
      "\n",
      "\n",
      "\n",
      "Iteration: 2000, Loss: 21.260548\n",
      "\n",
      "Ikytsodharidweonm\n",
      "En\n",
      "Eytrodharidweonm\n",
      "Idaaeor\n",
      "Yuuran\n",
      "Ab\n",
      "Tsodidkievdllr\n",
      "Aaepsac\n",
      "Todidkievdllr\n",
      "\n",
      "\n",
      "\n",
      "Iteration: 4000, Loss: 18.452282\n",
      "\n",
      "Jaytri\n",
      "Heh\n",
      "Hyvrn\n",
      "Jac\n",
      "Yuur\n",
      "Ab\n",
      "Uus\n",
      "A\n",
      "Tohfanbcxerir\n",
      "\n",
      "\n",
      "\n",
      "Iteration: 6000, Loss: 17.727077\n",
      "\n",
      "Kayson\n",
      "Haia\n",
      "Huvon\n",
      "Kac\n",
      "Ytrlan\n",
      "Caagon\n",
      "Utoi\n",
      "Aagoo\n",
      "Togibkfayer\n",
      "Aespe\n",
      "\n",
      "\n",
      "Iteration: 8000, Loss: 17.362597\n",
      "\n",
      "Keyvor\n",
      "Haic\n",
      "Hyvro\n",
      "Kacahisabarrevailumadyakir\n",
      "Yuvian\n",
      "Baafroi\n",
      "Uusan\n",
      "Aafroi\n",
      "Tpardin\n",
      "Ahote\n",
      "\n",
      "\n",
      "Iteration: 10000, Loss: 17.050682\n",
      "\n",
      "Keytrial\n",
      "Ilea\n",
      "Iytsn\n",
      "Kad\n",
      "Zstpbien\n",
      "Caahis\n",
      "Uusamaribujlis\n",
      "Aagro\n",
      "Tojeen\n",
      "Ahnse\n",
      "\n",
      "\n",
      "Iteration: 12000, Loss: 16.687856\n",
      "\n",
      "Kayton\n",
      "Geed\n",
      "Huuto\n",
      "Kacaeqsad\n",
      "Yuto\n",
      "Caagon\n",
      "Utohah\n",
      "Aaerol\n",
      "Toen\n",
      "Ador\n",
      "\n",
      "\n",
      "Iteration: 14000, Loss: 16.618971\n",
      "\n",
      "Keytri\n",
      "Imad\n",
      "Juvon\n",
      "Kad\n",
      "Yutr\n",
      "Baahio\n",
      "Uusan\n",
      "Aagon\n",
      "Tran\n",
      "Ahrom\n",
      "\n",
      "\n",
      "Iteration: 16000, Loss: 16.730751\n",
      "\n",
      "Leyson\n",
      "Jehaajio\n",
      "Kytsol\n",
      "Lacaen\n",
      "Zrysen\n",
      "Daafor\n",
      "Voran\n",
      "Aador\n",
      "Usen\n",
      "Afpred\n",
      "\n",
      "\n",
      "Iteration: 18000, Loss: 16.415764\n",
      "\n",
      "Keystoam\n",
      "Ilac\n",
      "Juwson\n",
      "Kad\n",
      "Zous\n",
      "Caaion\n",
      "Voran\n",
      "Aagrom\n",
      "Usdeel\n",
      "Aerre\n",
      "\n",
      "\n",
      "Iteration: 20000, Loss: 16.477289\n",
      "\n",
      "Keytrn\n",
      "Haga\n",
      "Hytso\n",
      "Kac\n",
      "Zrttan\n",
      "Caafor\n",
      "Vosan\n",
      "Aaeron\n",
      "Tpan\n",
      "Aessaa\n",
      "\n",
      "\n",
      "Iteration: 22000, Loss: 16.581739\n",
      "\n",
      "Keytro\n",
      "Ilda\n",
      "Juwon\n",
      "Kacagor\n",
      "Zovich\n",
      "Caadluk\n",
      "Viran\n",
      "Aadluk\n",
      "Toghaon\n",
      "Aestea\n",
      "\n",
      "\n",
      "Iteration: 24000, Loss: 16.452980\n",
      "\n",
      "Keysto\n",
      "Hbeb\n",
      "Izoso\n",
      "Kacairi\n",
      "Zstofe\n",
      "Caadrqbabloni\n",
      "Voram\n",
      "Aadpre\n",
      "Usan\n",
      "Aersa\n",
      "\n",
      "\n",
      "Iteration: 26000, Loss: 16.378789\n",
      "\n",
      "Kaysto\n",
      "Ilac\n",
      "Juvon\n",
      "Kab\n",
      "Zrusan\n",
      "Caagro\n",
      "Voram\n",
      "Aaesta\n",
      "Toen\n",
      "Adpre\n",
      "\n",
      "\n",
      "Iteration: 28000, Loss: 16.445915\n",
      "\n",
      "Keyson\n",
      "Jaha\n",
      "Juvor\n",
      "Lacaen\n",
      "Zrrode\n",
      "Caahor\n",
      "Voram\n",
      "Aador\n",
      "Tran\n",
      "Aerr\n",
      "\n",
      "\n",
      "Iteration: 30000, Loss: 16.524842\n",
      "\n",
      "Mayssob\n",
      "Jahaaeil\n",
      "Kystod\n",
      "Macairo\n",
      "Zous\n",
      "Daaern\n",
      "Viran\n",
      "Aador\n",
      "Toen\n",
      "Agron\n",
      "\n",
      "\n",
      "Iteration: 32000, Loss: 16.355376\n",
      "\n",
      "Lhystod\n",
      "Jeha\n",
      "Juvioj\n",
      "Lad\n",
      "Zrus\n",
      "Caafor\n",
      "Viran\n",
      "Aador\n",
      "Vian\n",
      "Ahosad\n",
      "\n",
      "\n",
      "Iteration: 34000, Loss: 16.374416\n",
      "\n",
      "Keytrn\n",
      "Inda\n",
      "Jwsxten\n",
      "Kacairk\n",
      "Zussan\n",
      "Caaeroh\n",
      "Ussan\n",
      "Aadrrac\n",
      "Trandon\n",
      "Ahron\n",
      "\n",
      "\n",
      "Iteration: 36000, Loss: 16.460417\n",
      "\n",
      "Keyson\n",
      "Jaha\n",
      "Juvnof\n",
      "Kac\n",
      "Zrrn\n",
      "Caadon\n",
      "Ustan\n",
      "Aadro\n",
      "Tran\n",
      "Aersad\n",
      "\n",
      "\n",
      "Iteration: 38000, Loss: 16.314722\n",
      "\n",
      "Keyron\n",
      "Iok\n",
      "Jytro\n",
      "Kad\n",
      "Zvor\n",
      "Caador\n",
      "Vus\n",
      "Aadop\n",
      "Trciin\n",
      "Ahor\n",
      "\n",
      "\n",
      "Iteration: 40000, Loss: 16.310237\n",
      "\n",
      "Kaysto\n",
      "Ilab\n",
      "Juwss\n",
      "Kad\n",
      "Zotran\n",
      "Daadop\n",
      "Von\n",
      "Aadprac\n",
      "Togicie\n",
      "Adrsab\n",
      "\n",
      "\n",
      "Iteration: 42000, Loss: 16.264733\n",
      "\n",
      "Keysrn\n",
      "Jaha\n",
      "Juvon\n",
      "Lac\n",
      "Zous\n",
      "Caadon\n",
      "Voram\n",
      "Aador\n",
      "Trdien\n",
      "Adro\n",
      "\n",
      "\n",
      "Iteration: 44000, Loss: 16.438524\n",
      "\n",
      "Leysso\n",
      "Jefa\n",
      "Jvprob\n",
      "Lacaenaa\n",
      "Zustan\n",
      "Caadop\n",
      "Ustan\n",
      "Aadpre\n",
      "Trch\n",
      "Afrre\n",
      "\n",
      "\n",
      "Iteration: 46000, Loss: 16.288346\n",
      "\n",
      "Leyssn\n",
      "Jaic\n",
      "Juvon\n",
      "Lad\n",
      "Zstoil\n",
      "Caadon\n",
      "Vordeilacrbing\n",
      "Aador\n",
      "Usaman\n",
      "Ahosaa\n",
      "\n",
      "\n",
      "Iteration: 48000, Loss: 16.327376\n",
      "\n",
      "Keystoh\n",
      "Inca\n",
      "Juttoj\n",
      "Kad\n",
      "Zrvoin\n",
      "Caahor\n",
      "Ttran\n",
      "Aahroh\n",
      "Tran\n",
      "Afrre\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "parameters_b, iter_loss_b = model(boy_strings, ix_to_char, char_to_ix, num_iterations=50000)\n",
    "with open('drive/My Drive/Colab Notebooks/character level model/boy_params.txt', 'wb') as file:\n",
    "  pickle.dump(parameters_b, file)\n",
    "with open('drive/My Drive/Colab Notebooks/character level model/boy_iter_loss_b.txt', 'wb') as file:\n",
    "  pickle.dump(iter_loss_b, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GIrls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 5967
    },
    "colab_type": "code",
    "id": "WDcZcilkb2Cy",
    "outputId": "8c419b86-d08b-4b99-ebba-7c12de542c14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0, Loss: 32.945184\n",
      "\n",
      "Nkzxwtdmfqoeyhsqwasjjjvu\n",
      "Kneb\n",
      "Kzxwtdmfqoeyhsqwasjjjvu\n",
      "Neb\n",
      "Zxwtdmfqoeyhsqwasjjjvu\n",
      "Eb\n",
      "Xwtdmfqoeyhsqwasjjjvu\n",
      "B\n",
      "Wtdmfqoeyhsqwasjjjvu\n",
      "\n",
      "\n",
      "\n",
      "Iteration: 2000, Loss: 21.010473\n",
      "\n",
      "Kgyytramdinayanjsariiini\n",
      "Hie\n",
      "Iyturancmieyanitariiirn\n",
      "Kacahrse\n",
      "Yturancni\n",
      "Ba\n",
      "Uuranengayerjsariienm\n",
      "A\n",
      "Traneni\n",
      "\n",
      "\n",
      "\n",
      "Iteration: 4000, Loss: 18.334722\n",
      "\n",
      "Leyrnn\n",
      "Haia\n",
      "Hyssnah\n",
      "Laa\n",
      "Yrrjanaliavarisanagesramleya\n",
      "Aa\n",
      "Tsranamdaycketanahasoaltayeh\n",
      "A\n",
      "Sranamdaycketanahasoaltayeh\n",
      "\n",
      "\n",
      "\n",
      "Iteration: 6000, Loss: 17.455795\n",
      "\n",
      "Liynna\n",
      "Jka\n",
      "Kystoaaamgcycnly\n",
      "Lba\n",
      "Ystra\n",
      "Da\n",
      "Ttradaelay\n",
      "A\n",
      "Srala\n",
      "Aerra\n",
      "\n",
      "\n",
      "Iteration: 8000, Loss: 17.229444\n",
      "\n",
      "Leysni\n",
      "Kieb\n",
      "Kysslanameeyales\n",
      "Lecaenna\n",
      "Yrorah\n",
      "Daainn\n",
      "Sspbleni\n",
      "A\n",
      "Sranaleavarisanaharkannaya\n",
      "Airmaa\n",
      "\n",
      "\n",
      "Iteration: 10000, Loss: 16.856747\n",
      "\n",
      "Liyori\n",
      "Jela\n",
      "Jwusra\n",
      "Laca\n",
      "Ystlah\n",
      "Ca\n",
      "Turai\n",
      "A\n",
      "Srana\n",
      "Aenn\n",
      "\n",
      "\n",
      "Iteration: 12000, Loss: 16.926707\n",
      "\n",
      "Liyosi\n",
      "Jie\n",
      "Kystjah\n",
      "Lee\n",
      "Yttlen\n",
      "Da\n",
      "Usraiahaevdiloa\n",
      "A\n",
      "Soelana\n",
      "Ahnna\n",
      "\n",
      "\n",
      "Iteration: 14000, Loss: 16.517499\n",
      "\n",
      "Mayssode\n",
      "Jeibaanna\n",
      "Kyusrah\n",
      "Madaeroe\n",
      "Zsuralandatalin\n",
      "Caahnna\n",
      "Ttoheene\n",
      "A\n",
      "Sramani\n",
      "Ahosea\n",
      "\n",
      "\n",
      "Iteration: 16000, Loss: 16.371419\n",
      "\n",
      "Meyssman\n",
      "Jeed\n",
      "Kystokeelley\n",
      "Madahlya\n",
      "Zuvialane\n",
      "Daahmse\n",
      "Turalenh\n",
      "Aahnre\n",
      "Sranakh\n",
      "Ahosebamtetedeveh\n",
      "\n",
      "\n",
      "Iteration: 18000, Loss: 16.322700\n",
      "\n",
      "Leysti\n",
      "Ilad\n",
      "Iyssr\n",
      "Lacaenn\n",
      "Zouraa\n",
      "Baadlrh\n",
      "Trmalana\n",
      "Aadlri\n",
      "Soelena\n",
      "Aeste\n",
      "\n",
      "\n",
      "Iteration: 20000, Loss: 16.317845\n",
      "\n",
      "Meyusna\n",
      "Khadaher\n",
      "Kyttralee\n",
      "Madaisle\n",
      "Zustdiele\n",
      "Daadlya\n",
      "Uviemai\n",
      "Aadmon\n",
      "Ssdigie\n",
      "Ahnpe\n",
      "\n",
      "\n",
      "Iteration: 22000, Loss: 16.459185\n",
      "\n",
      "Meyrora\n",
      "Kela\n",
      "Kysslen\n",
      "Madadosa\n",
      "Zusodh\n",
      "Edaeroh\n",
      "Uuraiaa\n",
      "Aadrya\n",
      "Togiblian\n",
      "Aeste\n",
      "\n",
      "\n",
      "Iteration: 24000, Loss: 16.052929\n",
      "\n",
      "Meystla\n",
      "Lica\n",
      "Lystna\n",
      "Madabrne\n",
      "Zrriana\n",
      "Eaadrle\n",
      "Tprelingasendl\n",
      "Aahora\n",
      "Solialian\n",
      "Agrola\n",
      "\n",
      "\n",
      "Iteration: 26000, Loss: 16.140243\n",
      "\n",
      "Mdystlah\n",
      "Keka\n",
      "Kystoelah\n",
      "Madaeroe\n",
      "Yussana\n",
      "Daahlya\n",
      "Turaland\n",
      "Aagrne\n",
      "Ssbicha\n",
      "Ahore\n",
      "\n",
      "\n",
      "Iteration: 28000, Loss: 16.052785\n",
      "\n",
      "Mdyssi\n",
      "Khada\n",
      "Kyrtlen\n",
      "Mada\n",
      "Zutrelah\n",
      "Daadose\n",
      "Uvielene\n",
      "Aadroi\n",
      "Trenaigeta\n",
      "Aerse\n",
      "\n",
      "\n",
      "Iteration: 30000, Loss: 16.160527\n",
      "\n",
      "Liztur\n",
      "Jeed\n",
      "Kyrria\n",
      "Laca\n",
      "Zussalendan\n",
      "Caadroh\n",
      "Turai\n",
      "Aadrre\n",
      "Sralene\n",
      "Aerte\n",
      "\n",
      "\n",
      "Iteration: 32000, Loss: 16.007749\n",
      "\n",
      "Leyssi\n",
      "Keid\n",
      "Kyrssa\n",
      "Lada\n",
      "Zussae\n",
      "Daahnna\n",
      "Turdi\n",
      "Aagpon\n",
      "Ssana\n",
      "Agrola\n",
      "\n",
      "\n",
      "Iteration: 34000, Loss: 16.027839\n",
      "\n",
      "Meyros\n",
      "Jeia\n",
      "Kyrplen\n",
      "Madaher\n",
      "Zussbelih\n",
      "Daadlya\n",
      "Ttralena\n",
      "Aahlya\n",
      "Soghane\n",
      "Adlyga\n",
      "\n",
      "\n",
      "Iteration: 36000, Loss: 16.088605\n",
      "\n",
      "Leystra\n",
      "Jeja\n",
      "Kystoja\n",
      "Macaenn\n",
      "Zstoha\n",
      "Caagrola\n",
      "Turalene\n",
      "Aahnna\n",
      "Spamariat\n",
      "Afore\n",
      "\n",
      "\n",
      "Iteration: 38000, Loss: 16.046566\n",
      "\n",
      "Lizynn\n",
      "Kiec\n",
      "Kysslei\n",
      "Lea\n",
      "Zuurea\n",
      "Daahni\n",
      "Voselena\n",
      "Aadmi\n",
      "Tralena\n",
      "Aerre\n",
      "\n",
      "\n",
      "Iteration: 40000, Loss: 16.167146\n",
      "\n",
      "Mbystlai\n",
      "Kiec\n",
      "Kyrstel\n",
      "Madabrica\n",
      "Yussan\n",
      "Daaista\n",
      "Uviana\n",
      "Aaista\n",
      "Sohiancarailmana\n",
      "Ahmifa\n",
      "\n",
      "\n",
      "Iteration: 42000, Loss: 15.859681\n",
      "\n",
      "Maystla\n",
      "Kifa\n",
      "Kyrri\n",
      "Macafrke\n",
      "Yurna\n",
      "Daagroe\n",
      "Ttraicha\n",
      "Aafrofa\n",
      "Sraleli\n",
      "Ahrola\n",
      "\n",
      "\n",
      "Iteration: 44000, Loss: 15.959396\n",
      "\n",
      "Leysora\n",
      "Jgee\n",
      "Jvstoja\n",
      "Laca\n",
      "Yussai\n",
      "Caahnna\n",
      "Turaia\n",
      "Aahrola\n",
      "Ssciena\n",
      "Ahprea\n",
      "\n",
      "\n",
      "Iteration: 46000, Loss: 15.771213\n",
      "\n",
      "Leyrie\n",
      "Jefa\n",
      "Jwynna\n",
      "Laca\n",
      "Yusla\n",
      "Caaeroa\n",
      "Vorah\n",
      "Aahmy\n",
      "Traleia\n",
      "Ahnne\n",
      "\n",
      "\n",
      "Iteration: 48000, Loss: 15.989169\n",
      "\n",
      "Leystra\n",
      "Jmadaerra\n",
      "Jvyopana\n",
      "Lacahhh\n",
      "Yusselaia\n",
      "Caadrud\n",
      "Tusblengara\n",
      "Aadrya\n",
      "Soelene\n",
      "Agrola\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "% timeit\n",
    "parameters_g,iter_loss_g = model(girl_strings, ix_to_char, char_to_ix,num_iterations = 50000)\n",
    "\n",
    "with open('drive/My Drive/Colab Notebooks/character level model/girl_params.txt', 'wb') as file:\n",
    "  pickle.dump(parameters_g, file)\n",
    "with open('drive/My Drive/Colab Notebooks/character level model/girl_iter_loss_b.txt', 'wb') as file:\n",
    "  pickle.dump(iter_loss_g, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 5967
    },
    "colab_type": "code",
    "id": "paHmEzdGb2C6",
    "outputId": "892c07fd-f197-4209-feeb-843c185f958e",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0, Loss: 32.951783\n",
      "\n",
      "Nkzxwtdmfqoeyhsqwasjkjvu\n",
      "Kneb\n",
      "Kzxwtdmfqoeyhsqwasjkjvu\n",
      "Neb\n",
      "Zxwtdmfqoeyhsqwasjkjvu\n",
      "Eb\n",
      "Xwtdmfqoeyhsqwasjkjvu\n",
      "B\n",
      "Wtdmfqoeyhsqwasjkjvu\n",
      "\n",
      "\n",
      "\n",
      "Iteration: 2000, Loss: 21.279099\n",
      "\n",
      "Iiyssnalaneawaonn\n",
      "Gica\n",
      "Hytrialaneawaonn\n",
      "Ida\n",
      "Ytsnalaneawaonn\n",
      "A\n",
      "Utnalaneawaonn\n",
      "A\n",
      "Tochaneawaonn\n",
      "\n",
      "\n",
      "\n",
      "Iteration: 4000, Loss: 18.630176\n",
      "\n",
      "Kaysria\n",
      "Haja\n",
      "Hysriaa\n",
      "Kaa\n",
      "Yrriaa\n",
      "Aa\n",
      "Tsoelana\n",
      "A\n",
      "Spamane\n",
      "\n",
      "\n",
      "\n",
      "Iteration: 6000, Loss: 17.883091\n",
      "\n",
      "Leyssodeenmaykmes\n",
      "Jeibaeroka\n",
      "Juusokeenmaykmes\n",
      "Laa\n",
      "Yssoimanlayjnis\n",
      "Da\n",
      "Troflanlayiner\n",
      "A\n",
      "Soimanlayiner\n",
      "Ahora\n",
      "\n",
      "\n",
      "Iteration: 8000, Loss: 17.581611\n",
      "\n",
      "Lfyssi\n",
      "Jei\n",
      "Kytti\n",
      "Led\n",
      "Yttn\n",
      "Da\n",
      "Ttrah\n",
      "A\n",
      "Soje\n",
      "Ahor\n",
      "\n",
      "\n",
      "Iteration: 10000, Loss: 17.382188\n",
      "\n",
      "Khyssa\n",
      "Jie\n",
      "Jxysr\n",
      "Kad\n",
      "Zuvlak\n",
      "Caahin\n",
      "Tusan\n",
      "Aahlr\n",
      "Soki\n",
      "Ahqse\n",
      "\n",
      "\n",
      "Iteration: 12000, Loss: 17.352950\n",
      "\n",
      "Keysih\n",
      "Jaia\n",
      "Juush\n",
      "Kad\n",
      "Yuto\n",
      "Caahen\n",
      "Ttra\n",
      "Aaion\n",
      "Sole\n",
      "Aisol\n",
      "\n",
      "\n",
      "Iteration: 14000, Loss: 17.148203\n",
      "\n",
      "Leystn\n",
      "Jiee\n",
      "Kysto\n",
      "Lee\n",
      "Zutra\n",
      "Daaisr\n",
      "Uurch\n",
      "Aaiss\n",
      "Tolibma\n",
      "Ahrre\n",
      "\n",
      "\n",
      "Iteration: 16000, Loss: 16.920076\n",
      "\n",
      "Keystobedin\n",
      "Jeic\n",
      "Jutrlak\n",
      "Kacaenn\n",
      "Ztrmah\n",
      "Daahlna\n",
      "Trlcieleatbris\n",
      "Aahora\n",
      "Soinah\n",
      "Ahpre\n",
      "\n",
      "\n",
      "Iteration: 18000, Loss: 16.828354\n",
      "\n",
      "Leysto\n",
      "Kida\n",
      "Kysto\n",
      "Lacadluf\n",
      "Yussamane\n",
      "Daadisa\n",
      "Ttpelana\n",
      "Aaeroh\n",
      "Sralend\n",
      "Agosa\n",
      "\n",
      "\n",
      "Iteration: 20000, Loss: 16.682538\n",
      "\n",
      "Leyssk\n",
      "Kiea\n",
      "Kytso\n",
      "Laca\n",
      "Yuspan\n",
      "Daahir\n",
      "Tusan\n",
      "Aahloh\n",
      "Tran\n",
      "Ahos\n",
      "\n",
      "\n",
      "Iteration: 22000, Loss: 16.694427\n",
      "\n",
      "Liyron\n",
      "Jied\n",
      "Jysto\n",
      "Lae\n",
      "Yussak\n",
      "Daadlo\n",
      "Ttree\n",
      "Aahmid\n",
      "Trel\n",
      "Ahrre\n",
      "\n",
      "\n",
      "Iteration: 24000, Loss: 16.600438\n",
      "\n",
      "Keyson\n",
      "Jeee\n",
      "Juxtol\n",
      "Kadadlm\n",
      "Zuvial\n",
      "Caahir\n",
      "Ttoil\n",
      "Aafrol\n",
      "Sofian\n",
      "Aessa\n",
      "\n",
      "\n",
      "Iteration: 26000, Loss: 16.739445\n",
      "\n",
      "Liysto\n",
      "Jefa\n",
      "Jystoh\n",
      "Lebaenn\n",
      "Zvorai\n",
      "Daadro\n",
      "Uusen\n",
      "Aador\n",
      "Tramcki\n",
      "Ahose\n",
      "\n",
      "\n",
      "Iteration: 28000, Loss: 16.511916\n",
      "\n",
      "Liyron\n",
      "Jela\n",
      "Jutusamaridyangrariiinn\n",
      "Lad\n",
      "Zussan\n",
      "Caahisa\n",
      "Ttreland\n",
      "Aadora\n",
      "Srenamahullir\n",
      "Ahnol\n",
      "\n",
      "\n",
      "Iteration: 30000, Loss: 16.579012\n",
      "\n",
      "Leyona\n",
      "Jica\n",
      "Jutto\n",
      "Laca\n",
      "Ztspacale\n",
      "Caahnn\n",
      "Von\n",
      "Aagro\n",
      "Tole\n",
      "Ahroe\n",
      "\n",
      "\n",
      "Iteration: 32000, Loss: 16.752098\n",
      "\n",
      "Keysto\n",
      "Jefa\n",
      "Jutus\n",
      "Kadaisoa\n",
      "Zrrode\n",
      "Caagro\n",
      "Ustan\n",
      "Aaestd\n",
      "Tranail\n",
      "Ahnoa\n",
      "\n",
      "\n",
      "Iteration: 34000, Loss: 16.642290\n",
      "\n",
      "Keyson\n",
      "Jica\n",
      "Juttoge\n",
      "Leb\n",
      "Zustan\n",
      "Caahnn\n",
      "Tusbead\n",
      "Aafor\n",
      "Soildh\n",
      "Aerra\n",
      "\n",
      "\n",
      "Iteration: 36000, Loss: 16.549246\n",
      "\n",
      "Lezssi\n",
      "Jeha\n",
      "Jvous\n",
      "Lacairo\n",
      "Zusrah\n",
      "Daahir\n",
      "Vorai\n",
      "Aahnod\n",
      "Tren\n",
      "Ahrre\n",
      "\n",
      "\n",
      "Iteration: 38000, Loss: 16.536976\n",
      "\n",
      "Leysslee\n",
      "Jeia\n",
      "Kysto\n",
      "Lee\n",
      "Zysrae\n",
      "Daadis\n",
      "Wsselan\n",
      "Aahisa\n",
      "Viem\n",
      "Aisse\n",
      "\n",
      "\n",
      "Iteration: 40000, Loss: 16.517665\n",
      "\n",
      "Lizsto\n",
      "Jela\n",
      "Jyttobh\n",
      "Lad\n",
      "Zuvian\n",
      "Caahmia\n",
      "Voraiah\n",
      "Aafro\n",
      "Tralena\n",
      "Aiste\n",
      "\n",
      "\n",
      "Iteration: 42000, Loss: 16.451036\n",
      "\n",
      "Keysri\n",
      "Ilea\n",
      "Jvrriam\n",
      "Kadaann\n",
      "Zuviak\n",
      "Caairo\n",
      "Turaiela\n",
      "Aairra\n",
      "Toimale\n",
      "Ahrri\n",
      "\n",
      "\n",
      "Iteration: 44000, Loss: 16.520034\n",
      "\n",
      "Keystod\n",
      "Imac\n",
      "Izussa\n",
      "Kad\n",
      "Yutsan\n",
      "Baahno\n",
      "Ttren\n",
      "Aahrre\n",
      "Spanden\n",
      "Ahrre\n",
      "\n",
      "\n",
      "Iteration: 46000, Loss: 16.591193\n",
      "\n",
      "Lizyon\n",
      "Jeib\n",
      "Jystole\n",
      "Ledainn\n",
      "Yrsten\n",
      "Caakste\n",
      "Tyolian\n",
      "Aahron\n",
      "Sranene\n",
      "Ahste\n",
      "\n",
      "\n",
      "Iteration: 48000, Loss: 16.738010\n",
      "\n",
      "Leysri\n",
      "Jeic\n",
      "Juttod\n",
      "Lacaenda\n",
      "Ytrlem\n",
      "Daagpre\n",
      "Ttolfan\n",
      "Aafroh\n",
      "Sranaib\n",
      "Ahrol\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parameters_c, iter_loss_c = model(combined_strings, ix_to_char, char_to_ix,num_iterations = 50000)\n",
    "with open('drive/My Drive/Colab Notebooks/character level model/c_params.txt', 'wb') as file:\n",
    "  pickle.dump(parameters_c, file)\n",
    "with open('drive/My Drive/Colab Notebooks/character level model/boy_iter_loss_c.txt', 'wb') as file:\n",
    "  pickle.dump(iter_loss_c, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jMTxCDP8b2DB"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rK_GtN6Sks_5"
   },
   "outputs": [],
   "source": [
    "x = pd.DataFrame(iter_loss_b, index = range(len(iter_loss_b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "LellrSGdlcm-",
    "outputId": "f9ac66e7-e3f0-40d5-9049-33a85a042043"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f008870de10>"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAAFKCAYAAABcq1WoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f00886046d8>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the saved weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8QNL0g2Urhyq"
   },
   "outputs": [],
   "source": [
    "with open('drive/My Drive/Colab Notebooks/character level model/boy_params.txt', 'wb') as file:\n",
    "  pickle.dump(parameters, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cJw4HpE-wMu9"
   },
   "outputs": [],
   "source": [
    "# reading Pickle file\n",
    "def read_pickle(path):\n",
    "  objects = []\n",
    "  with (open(path, \"rb\")) as openfile:\n",
    "      while True:\n",
    "          try:\n",
    "              objects.append(pickle.load(openfile))\n",
    "          except EOFError:\n",
    "              break\n",
    "  return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1LWybJIzOI4G"
   },
   "outputs": [],
   "source": [
    "boy_iter = read_pickle('drive/My Drive/Colab Notebooks/character level model/boy_iter_loss_b.txt')\n",
    "boy_params = read_pickle('drive/My Drive/Colab Notebooks/character level model/boy_params.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 9847
    },
    "colab_type": "code",
    "id": "IoWmqsluOzpM",
    "outputId": "4e664ad7-2aa9-409c-a7ce-f909a6fd139d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Waa': array([[-0.00500982,  0.01631995, -0.00216826, ...,  0.00880142,\n",
       "         -0.00337585,  0.00439502],\n",
       "        [ 0.00789849, -0.00437543,  0.01317384, ..., -0.00150877,\n",
       "         -0.00148728,  0.01021571],\n",
       "        [-0.01154183, -0.00571715, -0.00036941, ...,  0.00178756,\n",
       "          0.00616333, -0.00020538],\n",
       "        ...,\n",
       "        [ 0.00308257,  0.00690143,  0.01186455, ...,  0.00342417,\n",
       "          0.00358696, -0.013164  ],\n",
       "        [ 0.00955497, -0.00586507, -0.00239647, ..., -0.00640822,\n",
       "          0.01114331, -0.00129419],\n",
       "        [ 0.01271503, -0.02140724,  0.00037829, ...,  0.02295093,\n",
       "         -0.01721804,  0.00894287]]),\n",
       " 'Wax': array([[ 0.01624345, -0.06383082, -0.18113521, ...,  0.13468916,\n",
       "          0.05862426,  0.0503086 ],\n",
       "        [-0.00935769, -0.21490386,  0.08396738, ...,  0.06514132,\n",
       "         -0.05091902, -0.02617031],\n",
       "        [-0.00208894,  0.14592238,  0.25981087, ...,  0.19239539,\n",
       "          0.12667525,  0.38643273],\n",
       "        ...,\n",
       "        [ 0.0035927 ,  0.07124523, -0.12908443, ..., -0.03408024,\n",
       "         -0.17972156, -0.07694164],\n",
       "        [ 0.00604361,  0.14105483,  0.13945356, ...,  0.13350588,\n",
       "          0.14017797, -0.00411276],\n",
       "        [-0.01353754,  0.23969555,  0.09627578, ...,  0.14725652,\n",
       "          0.17254178,  0.02288825]]),\n",
       " 'Wya': array([[-0.03401977,  0.0021458 ,  0.14951519, ..., -0.08690587,\n",
       "          0.074079  ,  0.06736766],\n",
       "        [ 0.04859479,  0.05118921,  0.04526236, ..., -0.0838692 ,\n",
       "          0.01727573,  0.02715059],\n",
       "        [-0.07744941, -0.03212537, -0.10868182, ...,  0.02585292,\n",
       "         -0.02871692,  0.04232531],\n",
       "        ...,\n",
       "        [ 0.09997984, -0.05261897, -0.07434744, ...,  0.04564898,\n",
       "         -0.02270245,  0.01210752],\n",
       "        [-0.03580408,  0.01979682,  0.08856314, ...,  0.02724977,\n",
       "         -0.01222935,  0.06415711],\n",
       "        [-0.00531084, -0.06852388, -0.04885038, ..., -0.00743334,\n",
       "         -0.08185748, -0.01648795]]),\n",
       " 'b': array([[-6.74001888e-03],\n",
       "        [ 3.30335943e-02],\n",
       "        [-1.71094439e-01],\n",
       "        [-6.76960043e-02],\n",
       "        [-7.17986543e-02],\n",
       "        [-1.98181958e-01],\n",
       "        [-2.35401847e-02],\n",
       "        [-1.28251560e-01],\n",
       "        [-5.56612377e-03],\n",
       "        [ 1.91141638e-01],\n",
       "        [-6.11414375e-02],\n",
       "        [-2.70072663e-02],\n",
       "        [ 9.11238467e-02],\n",
       "        [ 3.61791429e-02],\n",
       "        [ 4.16687731e-02],\n",
       "        [ 2.54079380e-01],\n",
       "        [-2.15761504e-02],\n",
       "        [-1.24159091e-02],\n",
       "        [-3.98220781e-02],\n",
       "        [-1.44410923e-01],\n",
       "        [ 3.65454154e-02],\n",
       "        [-1.41320034e-01],\n",
       "        [-1.07123192e-01],\n",
       "        [-6.78440455e-02],\n",
       "        [ 4.48246846e-02],\n",
       "        [-9.98599047e-02],\n",
       "        [ 1.06132617e-01],\n",
       "        [ 8.14623112e-02],\n",
       "        [ 1.38575150e-01],\n",
       "        [-1.02124897e-01],\n",
       "        [ 2.94194701e-02],\n",
       "        [-1.44204017e-01],\n",
       "        [-5.85849874e-02],\n",
       "        [ 1.17172647e-01],\n",
       "        [-6.20146197e-03],\n",
       "        [ 6.72221163e-02],\n",
       "        [ 4.75185953e-02],\n",
       "        [ 1.42152176e-01],\n",
       "        [ 1.07042898e-01],\n",
       "        [-1.86867202e-01],\n",
       "        [-3.36380839e-02],\n",
       "        [ 9.39523155e-03],\n",
       "        [-8.05528511e-02],\n",
       "        [-4.39992566e-03],\n",
       "        [-1.16877889e-01],\n",
       "        [ 3.82921554e-02],\n",
       "        [ 1.39315321e-01],\n",
       "        [ 8.77101317e-02],\n",
       "        [-9.55204195e-02],\n",
       "        [-1.92063726e-01],\n",
       "        [ 6.03147958e-02],\n",
       "        [ 1.63143976e-01],\n",
       "        [-1.81254150e-01],\n",
       "        [ 1.35174640e-01],\n",
       "        [ 1.14793056e-01],\n",
       "        [-2.13418526e-01],\n",
       "        [ 1.95498977e-02],\n",
       "        [-4.84525155e-02],\n",
       "        [-9.37022863e-02],\n",
       "        [-1.58688329e-02],\n",
       "        [-1.00706126e-01],\n",
       "        [-2.16004849e-02],\n",
       "        [-1.67380706e-02],\n",
       "        [ 1.73140328e-01],\n",
       "        [ 4.19110938e-02],\n",
       "        [ 4.91222421e-02],\n",
       "        [ 2.44229148e-02],\n",
       "        [ 1.21971335e-03],\n",
       "        [-8.15482930e-03],\n",
       "        [-1.40912055e-02],\n",
       "        [-2.31265466e-01],\n",
       "        [-1.48600370e-01],\n",
       "        [-3.65677272e-03],\n",
       "        [-8.88674677e-02],\n",
       "        [-4.73869092e-02],\n",
       "        [-9.43129569e-02],\n",
       "        [-1.12893652e-01],\n",
       "        [ 6.68724379e-02],\n",
       "        [ 1.48687274e-01],\n",
       "        [ 1.39706604e-02],\n",
       "        [-5.63877438e-02],\n",
       "        [ 5.09856710e-02],\n",
       "        [-1.18316532e-01],\n",
       "        [-2.38838159e-01],\n",
       "        [ 3.48551929e-02],\n",
       "        [ 1.99154238e-01],\n",
       "        [ 8.09173787e-02],\n",
       "        [-8.44770755e-03],\n",
       "        [-1.83600001e-01],\n",
       "        [-3.07765599e-02],\n",
       "        [ 6.83319658e-02],\n",
       "        [-1.76358890e-02],\n",
       "        [-2.98486647e-02],\n",
       "        [ 1.86095432e-01],\n",
       "        [ 2.78402049e-02],\n",
       "        [ 1.34915399e-01],\n",
       "        [-2.89006957e-02],\n",
       "        [-8.33584574e-02],\n",
       "        [ 1.02217533e-01],\n",
       "        [ 9.96281063e-02],\n",
       "        [-5.93126845e-02],\n",
       "        [-1.64564378e-01],\n",
       "        [ 2.99679425e-02],\n",
       "        [ 5.35916292e-02],\n",
       "        [-4.30460205e-02],\n",
       "        [-1.59902307e-02],\n",
       "        [-1.28181932e-01],\n",
       "        [ 9.55412194e-02],\n",
       "        [-2.71661378e-02],\n",
       "        [ 9.36155412e-02],\n",
       "        [ 4.43157433e-02],\n",
       "        [ 2.75904876e-04],\n",
       "        [ 8.04436696e-03],\n",
       "        [-1.64740149e-01],\n",
       "        [ 1.06182996e-01],\n",
       "        [ 1.00821664e-01],\n",
       "        [-3.01910473e-02],\n",
       "        [ 7.08886467e-02],\n",
       "        [-6.42574447e-02],\n",
       "        [-2.37776023e-02],\n",
       "        [ 4.56264277e-02],\n",
       "        [ 5.45873726e-02],\n",
       "        [ 6.95339008e-02],\n",
       "        [-1.36198571e-01],\n",
       "        [-5.12066548e-02],\n",
       "        [ 4.68151987e-02],\n",
       "        [-2.40916463e-02],\n",
       "        [-2.04512694e-02],\n",
       "        [ 6.48399928e-02],\n",
       "        [ 9.29037509e-02],\n",
       "        [-6.01462953e-02],\n",
       "        [ 4.60552112e-02],\n",
       "        [-2.04817584e-03],\n",
       "        [-1.50841819e-02],\n",
       "        [-7.15062584e-02],\n",
       "        [ 6.61175571e-02],\n",
       "        [-1.84265332e-01],\n",
       "        [ 5.81801157e-02],\n",
       "        [ 7.28786924e-02],\n",
       "        [ 8.14493288e-02],\n",
       "        [ 1.89418692e-01],\n",
       "        [-1.51285260e-01],\n",
       "        [ 1.07544376e-01],\n",
       "        [-7.64691083e-02],\n",
       "        [-1.30429364e-01],\n",
       "        [-1.08059784e-02],\n",
       "        [-7.48902765e-02],\n",
       "        [ 2.66625373e-02],\n",
       "        [-2.68605430e-02],\n",
       "        [-6.45076419e-02],\n",
       "        [ 2.21744957e-02],\n",
       "        [ 1.24478161e-02],\n",
       "        [ 4.97070834e-01],\n",
       "        [ 3.02248509e-02],\n",
       "        [-8.72928987e-02],\n",
       "        [ 3.01196788e-02],\n",
       "        [-2.10696602e-01],\n",
       "        [ 4.48264391e-03],\n",
       "        [-1.07121017e-01],\n",
       "        [-6.89461953e-02],\n",
       "        [ 2.50605533e-01],\n",
       "        [ 8.81512093e-03],\n",
       "        [ 2.17653791e-02],\n",
       "        [-1.74731483e-01],\n",
       "        [-1.36911976e-04],\n",
       "        [-7.22589302e-02],\n",
       "        [ 8.56506684e-02],\n",
       "        [-1.34325979e-01],\n",
       "        [-6.10655040e-02],\n",
       "        [-1.04892873e-01],\n",
       "        [ 4.88295816e-02],\n",
       "        [-1.86526263e-01],\n",
       "        [-6.66828097e-02],\n",
       "        [-4.81322383e-02],\n",
       "        [-8.16043143e-02],\n",
       "        [ 1.74867090e-02],\n",
       "        [ 4.32964950e-02],\n",
       "        [ 4.69998425e-02],\n",
       "        [-1.21816322e-01],\n",
       "        [-8.64796205e-02],\n",
       "        [-2.45675828e-02],\n",
       "        [-3.34439103e-02],\n",
       "        [-4.51274463e-02],\n",
       "        [ 1.32821638e-01],\n",
       "        [ 5.88103764e-02],\n",
       "        [ 1.72579482e-01],\n",
       "        [-3.91033645e-02],\n",
       "        [ 6.65735239e-02],\n",
       "        [ 1.58390117e-01],\n",
       "        [-1.84255610e-01],\n",
       "        [ 1.19741162e-01],\n",
       "        [ 1.68667466e-01],\n",
       "        [-1.11512507e-01],\n",
       "        [ 7.43039302e-02],\n",
       "        [-1.22827588e-01],\n",
       "        [-5.77560398e-02],\n",
       "        [ 1.75037662e-02],\n",
       "        [-1.92978435e-02],\n",
       "        [-7.86294882e-02],\n",
       "        [ 1.71772846e-01],\n",
       "        [-1.06323568e-01],\n",
       "        [-7.54659614e-02],\n",
       "        [-5.24499550e-02],\n",
       "        [ 2.51937941e-02],\n",
       "        [ 8.39027078e-03],\n",
       "        [ 1.45776457e-01],\n",
       "        [-8.12677864e-02],\n",
       "        [ 8.27038730e-02],\n",
       "        [ 1.45365136e-01],\n",
       "        [ 7.38937220e-02],\n",
       "        [ 1.09899136e-01],\n",
       "        [ 9.08878740e-02],\n",
       "        [-7.17287007e-02],\n",
       "        [-3.48410339e-02],\n",
       "        [ 6.73508936e-02],\n",
       "        [ 1.65328267e-01],\n",
       "        [-7.19819125e-02],\n",
       "        [ 1.55414481e-01],\n",
       "        [-1.03672020e-02],\n",
       "        [ 1.32563256e-01],\n",
       "        [-9.22002712e-03],\n",
       "        [-1.76162794e-02],\n",
       "        [ 8.80455498e-02],\n",
       "        [ 2.38894085e-02],\n",
       "        [ 4.84647472e-03],\n",
       "        [-7.42262494e-02],\n",
       "        [ 1.05574175e-01],\n",
       "        [-1.05134116e-01],\n",
       "        [-1.54786189e-01],\n",
       "        [-1.35019045e-01],\n",
       "        [ 8.00538159e-02],\n",
       "        [-1.05555117e-02],\n",
       "        [ 1.42047630e-01],\n",
       "        [-7.28143428e-02],\n",
       "        [-3.50474244e-02],\n",
       "        [ 3.08118843e-03],\n",
       "        [ 1.56971616e-02],\n",
       "        [-5.19201841e-02],\n",
       "        [-3.40306691e-02],\n",
       "        [ 6.96640489e-02],\n",
       "        [-1.53629333e-01],\n",
       "        [-1.12283145e-02],\n",
       "        [-6.00471225e-02],\n",
       "        [ 1.56897972e-01],\n",
       "        [-6.22577585e-02],\n",
       "        [-2.97651581e-02],\n",
       "        [-4.37194809e-02],\n",
       "        [ 9.41795500e-02],\n",
       "        [ 1.02260538e-02],\n",
       "        [-1.21790432e-01],\n",
       "        [ 1.15962954e-01],\n",
       "        [-7.88791615e-03],\n",
       "        [ 2.57099632e-01],\n",
       "        [-3.56303382e-02],\n",
       "        [ 2.00715133e-01],\n",
       "        [ 2.15461228e-02],\n",
       "        [-4.79898779e-02],\n",
       "        [-1.54121833e-01],\n",
       "        [-2.71132153e-02],\n",
       "        [-9.58330601e-02],\n",
       "        [ 5.42138214e-02],\n",
       "        [-4.76606476e-02],\n",
       "        [-5.06852438e-02],\n",
       "        [-2.83106807e-01],\n",
       "        [ 4.48609509e-02],\n",
       "        [ 2.15754721e-01],\n",
       "        [-1.40186659e-01],\n",
       "        [ 1.09743599e-01],\n",
       "        [-6.16894243e-02],\n",
       "        [ 2.06209957e-01],\n",
       "        [ 5.88649862e-03],\n",
       "        [-1.49983792e-02],\n",
       "        [ 1.46555717e-01],\n",
       "        [-1.02584661e-01],\n",
       "        [-4.69203250e-02],\n",
       "        [-7.01170725e-02],\n",
       "        [ 2.69983832e-01],\n",
       "        [ 7.22634204e-03],\n",
       "        [ 6.01112014e-02],\n",
       "        [ 1.76183417e-02],\n",
       "        [ 2.45024530e-01],\n",
       "        [-7.49592935e-02],\n",
       "        [-7.36280229e-02],\n",
       "        [ 1.48123498e-01],\n",
       "        [-5.10089253e-02],\n",
       "        [ 1.35819578e-01],\n",
       "        [-3.56574793e-02],\n",
       "        [-8.82393163e-03],\n",
       "        [-1.02091692e-01],\n",
       "        [-2.00426697e-02],\n",
       "        [ 7.32417763e-02],\n",
       "        [-3.08333465e-03],\n",
       "        [-5.07942286e-03],\n",
       "        [ 4.79450782e-02],\n",
       "        [-1.02743620e-01],\n",
       "        [-1.05827833e-01],\n",
       "        [ 1.46192852e-01],\n",
       "        [-8.78194532e-02],\n",
       "        [ 1.04413731e-01],\n",
       "        [-1.27268225e-01],\n",
       "        [-1.01459353e-01],\n",
       "        [-5.32821666e-02],\n",
       "        [-2.22542838e-02],\n",
       "        [-6.32829983e-02],\n",
       "        [ 9.91768265e-02],\n",
       "        [ 2.94327118e-01],\n",
       "        [-1.73216839e-01],\n",
       "        [-2.76371823e-03],\n",
       "        [-3.51665920e-02],\n",
       "        [ 5.70933483e-02],\n",
       "        [-2.02634684e-01],\n",
       "        [-6.18410382e-03],\n",
       "        [ 3.81429617e-02],\n",
       "        [-1.89122815e-02],\n",
       "        [-9.84187980e-02],\n",
       "        [-6.00807128e-02],\n",
       "        [-6.77255056e-03],\n",
       "        [ 1.35550000e-02],\n",
       "        [ 1.14816073e-02],\n",
       "        [-4.81900368e-02],\n",
       "        [ 4.95040796e-02],\n",
       "        [ 9.70146599e-02],\n",
       "        [ 6.78439106e-02],\n",
       "        [-1.40919517e-01],\n",
       "        [ 7.20850175e-02],\n",
       "        [ 1.69504920e-01],\n",
       "        [ 3.54465228e-02],\n",
       "        [-1.08792377e-02],\n",
       "        [ 9.08729525e-02],\n",
       "        [ 1.31970465e-01],\n",
       "        [-7.74164235e-02],\n",
       "        [ 6.92293506e-02],\n",
       "        [-1.97089260e-01],\n",
       "        [-9.16292405e-02],\n",
       "        [-6.32947195e-02],\n",
       "        [-6.99418308e-02],\n",
       "        [-8.31184716e-02],\n",
       "        [-2.05467521e-01],\n",
       "        [-1.92977201e-01],\n",
       "        [ 1.44748272e-01],\n",
       "        [-1.18409991e-01],\n",
       "        [ 1.00551176e-01],\n",
       "        [-2.15404515e-02],\n",
       "        [ 4.55841790e-02],\n",
       "        [ 5.90278854e-03],\n",
       "        [ 4.03311909e-02],\n",
       "        [-9.64822436e-03],\n",
       "        [ 5.14765999e-02],\n",
       "        [-1.80467891e-01],\n",
       "        [-5.30201907e-02],\n",
       "        [ 1.12999529e-01],\n",
       "        [-7.31948869e-02],\n",
       "        [-6.62342674e-02],\n",
       "        [ 4.03735720e-02],\n",
       "        [-7.83601649e-02],\n",
       "        [-1.24412533e-01],\n",
       "        [-7.53319270e-02],\n",
       "        [-8.05358507e-02],\n",
       "        [-3.90959773e-02],\n",
       "        [-5.94494346e-02],\n",
       "        [ 1.10141637e-01],\n",
       "        [ 4.74109878e-02],\n",
       "        [ 2.30563487e-01],\n",
       "        [ 8.08358798e-02],\n",
       "        [ 2.34808986e-01],\n",
       "        [ 9.73780256e-02],\n",
       "        [ 1.87048970e-01],\n",
       "        [-7.93718427e-02],\n",
       "        [ 4.72484505e-02],\n",
       "        [ 2.22976211e-02],\n",
       "        [-5.74949906e-02],\n",
       "        [ 8.58139306e-02],\n",
       "        [ 5.02262731e-02],\n",
       "        [ 8.68944962e-02],\n",
       "        [-1.24061970e-01],\n",
       "        [ 1.13396619e-01],\n",
       "        [ 2.79502767e-02],\n",
       "        [-1.38861513e-01],\n",
       "        [-5.70627591e-02],\n",
       "        [ 6.89773638e-02],\n",
       "        [ 1.05544514e-01],\n",
       "        [-1.28687549e-02],\n",
       "        [-2.55096325e-02],\n",
       "        [-1.41126374e-02],\n",
       "        [ 2.93196934e-02],\n",
       "        [ 7.57092605e-02],\n",
       "        [ 2.17890178e-01],\n",
       "        [ 4.25392824e-01],\n",
       "        [ 1.48220715e-01],\n",
       "        [-3.68469696e-03],\n",
       "        [-1.61297811e-01],\n",
       "        [-6.90565863e-02],\n",
       "        [ 1.88750736e-01],\n",
       "        [ 8.17255752e-02],\n",
       "        [-2.21945284e-01],\n",
       "        [-1.04102292e-01],\n",
       "        [-4.08657460e-02],\n",
       "        [ 1.58039553e-01],\n",
       "        [ 1.23994756e-01],\n",
       "        [ 1.08511613e-01],\n",
       "        [-8.45629166e-02],\n",
       "        [-1.15699746e-01],\n",
       "        [-7.66813594e-03],\n",
       "        [-1.23540135e-01],\n",
       "        [-2.26891068e-01],\n",
       "        [-9.36431064e-02],\n",
       "        [ 2.24562601e-02],\n",
       "        [ 8.33938949e-02],\n",
       "        [ 1.18468305e-01],\n",
       "        [-2.29700838e-01],\n",
       "        [-2.04027799e-01],\n",
       "        [-7.17508855e-03],\n",
       "        [-1.28886292e-02],\n",
       "        [-8.24645164e-02],\n",
       "        [ 6.09775175e-02],\n",
       "        [ 1.68111141e-02],\n",
       "        [-1.40957437e-01],\n",
       "        [-8.43021800e-02],\n",
       "        [ 6.96599743e-02],\n",
       "        [ 2.13663348e-02],\n",
       "        [ 1.51364674e-02],\n",
       "        [ 1.15228424e-02],\n",
       "        [-9.99594136e-02],\n",
       "        [ 4.19922991e-02],\n",
       "        [-2.01417189e-01],\n",
       "        [ 1.74033854e-02],\n",
       "        [ 4.84905894e-02],\n",
       "        [ 7.37853715e-02],\n",
       "        [-1.20524035e-01],\n",
       "        [ 2.01143885e-02],\n",
       "        [-3.50383384e-03],\n",
       "        [-3.22381057e-02],\n",
       "        [ 2.48337595e-01],\n",
       "        [ 2.05132973e-01],\n",
       "        [-1.18377827e-01],\n",
       "        [-5.50530847e-02],\n",
       "        [-3.31434768e-02],\n",
       "        [-1.20438717e-02],\n",
       "        [ 1.74533773e-01],\n",
       "        [ 2.27006417e-01],\n",
       "        [ 4.70964230e-03],\n",
       "        [-2.02261226e-02],\n",
       "        [-4.74557253e-02],\n",
       "        [ 1.61988238e-01],\n",
       "        [-1.28998182e-01],\n",
       "        [ 7.64346220e-02],\n",
       "        [-1.13073769e-01],\n",
       "        [ 9.26165172e-02],\n",
       "        [ 1.09495324e-01],\n",
       "        [-2.76957138e-01],\n",
       "        [-6.76755184e-02],\n",
       "        [ 1.19975487e-01],\n",
       "        [ 1.72364729e-03],\n",
       "        [-3.22251407e-02],\n",
       "        [ 1.94283550e-02],\n",
       "        [ 4.22580814e-02],\n",
       "        [-1.05412429e-01],\n",
       "        [ 8.02072646e-02],\n",
       "        [-7.94666385e-02],\n",
       "        [-3.88694150e-02],\n",
       "        [-2.63105765e-01],\n",
       "        [-6.22690069e-02],\n",
       "        [-2.39136285e-02],\n",
       "        [-1.74480851e-02],\n",
       "        [ 7.02280839e-02],\n",
       "        [ 7.79044084e-02],\n",
       "        [ 1.02873497e-01],\n",
       "        [-9.52645541e-02],\n",
       "        [ 2.45642907e-02],\n",
       "        [-6.29648335e-02],\n",
       "        [-4.13471277e-02],\n",
       "        [ 1.43963262e-01],\n",
       "        [-2.28400015e-03],\n",
       "        [ 3.93440772e-02],\n",
       "        [ 2.29377268e-01],\n",
       "        [ 1.63738638e-02],\n",
       "        [ 7.34369903e-04],\n",
       "        [-9.01778335e-03],\n",
       "        [ 6.27479790e-02],\n",
       "        [ 1.83991067e-02],\n",
       "        [ 7.66064046e-02],\n",
       "        [ 3.89948074e-02],\n",
       "        [ 9.68304571e-02],\n",
       "        [-5.42572563e-02],\n",
       "        [ 2.80943020e-01],\n",
       "        [-1.51719942e-01],\n",
       "        [ 1.26356294e-01],\n",
       "        [-1.25787932e-01],\n",
       "        [ 3.02834065e-01],\n",
       "        [ 4.20111642e-02],\n",
       "        [ 1.32945954e-03],\n",
       "        [-1.17449589e-01],\n",
       "        [-1.05052879e-01],\n",
       "        [-2.47108601e-02],\n",
       "        [-1.49542792e-01],\n",
       "        [-2.99011836e-02],\n",
       "        [-1.57209424e-02],\n",
       "        [ 3.46525741e-02],\n",
       "        [-9.45727048e-02],\n",
       "        [-1.13776123e-01]]),\n",
       " 'by': array([[-0.99616001],\n",
       "        [ 2.02273028],\n",
       "        [-0.21825871],\n",
       "        [-0.10266429],\n",
       "        [ 0.51429816],\n",
       "        [ 1.48060259],\n",
       "        [-1.32012936],\n",
       "        [-0.68752742],\n",
       "        [ 0.39416697],\n",
       "        [ 1.21416261],\n",
       "        [-0.5312593 ],\n",
       "        [ 0.03737319],\n",
       "        [ 0.77306037],\n",
       "        [ 0.55586124],\n",
       "        [ 0.36491679],\n",
       "        [ 0.74102269],\n",
       "        [-1.17928448],\n",
       "        [-2.27006668],\n",
       "        [ 1.28902004],\n",
       "        [ 0.67993933],\n",
       "        [ 0.36408414],\n",
       "        [-0.11705517],\n",
       "        [-0.55919457],\n",
       "        [-1.1616517 ],\n",
       "        [-1.61264302],\n",
       "        [ 0.75711136],\n",
       "        [-0.4224329 ]])}"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boy_params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yjhgeN-ANMp6"
   },
   "outputs": [],
   "source": [
    "boy_iter  = pd.DataFrame(data = boy_iter[0],columns = ['loss_b'],index = range(len(boy_iter[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "byLbCw1nNOwA",
    "outputId": "c3ccda03-14e1-4884-8230-5070b3e7b457"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ffa0f2bef98>"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFKCAYAAAAnj5dkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xl8VPW9//HXZCYzk0kmySRMEraw\nhH0XxQUUBSlVrG21hVIvLo9aa6W40B8CohXv9SoVu6m9LYrS1tbWtGgtWqoUl4rKIqgskS2AEAJk\n3zNZZvn9ERiNBBIyk8z2fv6VzJwz85kPJO98v+d7zjH4fD4fIiIiEjbiQl2AiIiItKZwFhERCTMK\nZxERkTCjcBYREQkzCmcREZEwo3AWEREJM6ZQF3BKSUlNUF/P4bBRUVEf1NeMNephcKiPgVMPA6ce\nBkcw++h02s/4XNSOnE0mY6hLiHjqYXCoj4FTDwOnHgZHd/UxasNZREQkUimcRUREwozCWUREJMwo\nnEVERMKMwllERCTMKJxFRETCjMJZREQkzCicRUREwozCWUREot7ata/y61//qkte+5prrgz6ayqc\nRUREwkzYXFs7mApLajla7qJPWkKoSxERkS/461v5fLinOKivOWFYBrOmDurY+//1L7z55joALrvs\ncubMuYUtWzaxcuVvsFisOBxpLF36v3z00dbTHjOZzhyZv/rVz9iz51McjjQefvinZ922I6Jy5Jz7\nVj7/u2ozPp8v1KWIiEiYOH68kH/961X+7/9W8n//t5K33vo3hYVHeemlXObNm8+vf/0M06ZNp6qq\nss3HzqSqqopp077KihWrMBrj2LTpg4BrjcqRs8FgoMntpanZi8Wsi72LiISLWVMHdXiUG2z79u3j\noosu9o9qR48eS37+PqZMmcbjjy9j+vSrmDbtq6Sn92jzsTMxmy2MGjUagOHDR3LkyOGAa43KkbP1\nZCA3NLlDXImIiIQLg4FWM6rNzc0YDHFcddU1PPXUClJSUlm0aD6HD3/W5mNne93W3xva3vAcRHk4\ne0JciYiIhIshQ4aya9dO3G43brebTz/NY8iQofz+989iNJr4xjeu58orp/PZZwfbfOxMGhsb2bNn\nNwB5ebvo379/wLW2O63tcrlYvHgxZWVlNDY2MnfuXIYNG8Z9992H2+3GZDLx+OOP43Q6/fts3ryZ\nu+++m8GDBwMwZMgQfvKTnwRcbEdZFM4iIvIlWVm9OO+8C7jzzh/g9fq49tpvkJXVk8zMLO65Zy52\nezJ2u53Zs+dQX19/2mNn0qOHk3//+1889dQvcDjSuPDCSwKu1eBrZ9XU2rVrKSws5LbbbqOwsJDv\nfe97jBs3jssvv5wZM2bwwgsvUFhYyMKFC/37bN68mRdeeIEnn3yyw4WUlNR0/lN8ycvvHuS1Dz5j\n0Q3nMTTbEbTXjTVOpz2o/y6xSn0MnHoYOPUwOILZR6fTfsbn2h05z5gxw//18ePHyczMZOnSpVgs\nFgAcDgd5eXlBKDN4EjRyFhGRIHrvvf/w4osvYDabaPrCeqaZM7/L5ZdPCfr7dXi19uzZszlx4gQr\nVqzAZrMB4PF4+POf/8yPfvSj07bPz8/nhz/8IVVVVcybN49JkyYFr+p2nJrWbmxWOIuISOAuvfRy\nLr308m6bgWh3WvuLdu/ezcKFC1mzZg1er5eFCxcyYMAA5s2b12q7oqIitm3bxtVXX01BQQE33XQT\n69atw2w2n/G13W4PJlNwTnt6a2sBv/zLR8ybOY6vXtwvKK8pIiLSXdodOe/atYv09HR69uzJ8OHD\n8Xg8lJeX89hjj9GvX7/TghkgMzPTPx2enZ1Njx49KCoqom/fvmd8n4qK+gA+RmvNjc0AlJbX6RhL\nAHSMKjjUx8Cph4FTD4Oju445t3sq1datW1m1ahUApaWl1NfX8/777xMfH89dd93V5j5r1qzhueee\nA6CkpISysjIyMzM7U3unWHSes4iIRLB2R86zZ8/m/vvv54YbbqChoYEHH3yQZ555hsbGRm688UYA\ncnJyeOihh5g/fz7Lli1j6tSpLFiwgDfffJPm5mYeeuihs05pB5vOcxYRkUjWbjhbrVZ+/vOft3ps\n6tSpbW77y1/+0v/1ihUrAiyt86zmlo/VqHAWEZEIFJ1XCIvXtLaIiESu6Axni6a1RUQkckVlOFvi\nFc4iIhK5ojKcTcY44k1xCmcREYlIURnOAAkWk445i4hIRIrqcNblO0VEJBJFdTg3NCqcRUQk8kR3\nODd5OIdLh4uIiISFqA5nr8+H2+MNdSkiIiLnJGrD+dS5zi6t2BYRkQgTteGcYGm5hKdOpxIRkUgT\n9eGs62uLiEikifpw1rnOIiISaWIgnDVyFhGRyBL14axpbRERiTRRG86n7uns0rS2iIhEmKgN5wSr\nprVFRCQyRW84a1pbREQiVPSGs1kjZxERiUzRG85WnUolIiKRKXrDWdPaIiISoaI2nK3mlmtra1pb\nREQiTdSGs03T2iIiEqGiNpzjTUaMcQYamjVyFhGRyBK14QwtU9ua1hYRkUgT/eHcqHAWEZHIEuXh\nbKJR09oiIhJhojqcLWajFoSJiEjEiepwtpqNuD0+3B5vqEsRERHpsCgPZ13CU0REIk9Uh7Ml/tSF\nSDS1LSIikcPU3gYul4vFixdTVlZGY2Mjc+fOZdiwYSxcuBCPx4PT6eTxxx/HbDa32u/RRx9l+/bt\nGAwGlixZwpgxY7rsQ5yJ1aKrhImISORpN5zffvttRo0axW233UZhYSHf+973GD9+PDfccANXX301\nv/jFL1i9ejU33HCDf58tW7Zw+PBhcnNzOXDgAEuWLCE3N7dLP0hbTl3CU9fXFhGRSNLutPaMGTO4\n7bbbADh+/DiZmZls3ryZK6+8EoApU6awcePGVvts3LiRadOmAZCTk0NVVRW1tbXBrr1d1niNnEVE\nJPJ0+Jjz7NmzWbBgAUuWLMHlcvmnsdPT0ykpKWm1bWlpKQ6Hw/99Wlraadt0h88XhOmYs4iIRI52\np7VPefHFF9m9ezf33nsvPp/P//gXvz6TjmzjcNgwmYwdLadDnOmJAJit8Tid9qC+dqxQ34JDfQyc\nehg49TA4uqOP7Ybzrl27SE9Pp2fPngwfPhyPx0NiYiINDQ1YrVaKiorIyMhotU9GRgalpaX+74uL\ni3E6nWd9n4qK+k5+hLY5nXaaGptb3r+0jpKSmqC+fixwOu3qWxCoj4FTDwOnHgZHMPt4tpBvd1p7\n69atrFq1CmiZrq6vr2fixIm88cYbAKxbt47LLrus1T6TJk3yP5+Xl0dGRgZJSUmd/gCdpWltERGJ\nRO2OnGfPns3999/PDTfcQENDAw8++CCjRo1i0aJF5Obm0qtXL775zW8CMH/+fJYtW8b48eMZOXIk\ns2fPxmAwsHTp0i7/IG3xr9bW9bVFRCSCtBvOVquVn//856c9/rvf/e60x375y1/6v16wYEGApQXu\nVDjrzlQiIhJJovoKYf5w1qlUIiISQaI8nE8ec9a0toiIRJCoDmeLWdfWFhGRyBPV4Ww2xWEwaFpb\nREQiS1SHs8FgwGo26draIiISUaI6nKFlUZimtUVEJJLESDhr5CwiIpEjJsJZ09oiIhJJoj6cLfFG\nmtxePF5vqEsRERHpkKgP51PnOmv0LCIikSIGwllXCRMRkciicBYREQkzMRDOp24bqXAWEZHIEP3h\nbGkZObt0rrOIiESIqA9nm6Vl5OxqUDiLiEhkiP5wtraEc32jwllERCJDDIRzPAB1Dc0hrkRERKRj\noj+cT05r12taW0REIkTUh3OiVeEsIiKRJerD+dS0to45i4hIpIiBcG4ZOeuYs4iIRIqoD2ezKQ5j\nnEGnUomISMSI+nA2GAzYrCZNa4uISMSI+nCGluPOdRo5i4hIhIiNcLaYtFpbREQiRkyEc6LVhNvj\npalZN78QEZHwFxPhrEt4iohIJImRcD55rrOmtkVEJALERjjrEp4iIhJBYiOc/dPauhCJiIiEv5gK\nZ51OJSIikSA2wlnT2iIiEkFMHdlo+fLlbNu2Dbfbze23385rr71GRUUFAJWVlYwbN46HH37Yv/3L\nL7/ME088QXZ2NgATJ07kjjvu6ILyOybRvyBM09oiIhL+2g3nTZs2sX//fnJzc6moqOC6667jnXfe\n8T9/3333MXPmzNP2mzFjBosWLQpqsZ2lU6lERCSStBvOEyZMYMyYMQAkJyfjcrnweDwYjUYOHjxI\nTU2N//lwZdM9nUVEJIK0e8zZaDRis9kAWL16NZMnT8ZoNALw/PPPM2fOnDb327JlC7feeis333wz\nn376aRBLPnc65iwiIpGkQ8ecAdavX8/q1atZtWoVAE1NTWzbto2HHnrotG3Hjh1LWloaV1xxBR9/\n/DGLFi3i1VdfPevrOxw2TCbjuVXfDqfT3vLaHi8AzV6f/zHpGPUrONTHwKmHgVMPg6M7+tihcN6w\nYQMrVqzg2WefxW5vKerDDz8843R2Tk4OOTk5AJx33nmUl5f7p8LPpKKi/lxrPyun005JSY3/e4vZ\nSGVNQ6vH5Oy+3EPpHPUxcOph4NTD4AhmH88W8u1Oa9fU1LB8+XKefvppUlNT/Y/v3LmTYcOGtbnP\nypUree211wDYt28faWlpZw3m7qA7U4mISKRod+S8du1aKioquOeee/yPPfbYY5SUlPhPlTrljjvu\n4Le//S3XXnst9957Ly+++CJut5tHHnkk+JWfo0SriYqaxlCXISIi0i6Dz+fzhboIIOjTLV+eevjp\nn7ax/2gVKxdNIc5gCOp7RStNgwWH+hg49TBw6mFwhM20drSwWePxAQ2NuqeziIiEtxgK51OnU+kq\nYSIiEt5iJ5wtukqYiIhEhtgJZ92ZSkREIkQMhfOpm18onEVEJLzFTDgn+m9+oWPOIiIS3mImnHV9\nbRERiRSxE866M5WIiESIGApnHXMWEZHIEDvhbNExZxERiQwxE85JCS0j5xqXwllERMJbzISzxWzE\nYjZSXdsU6lJERETOKmbCGSAl0UxVncJZRETCW0yFc2qimer6JrzesLgRl4iISJtiKpyTkyz4fFBd\nr9GziIiEr5gK59REMwBVOu4sIiJhLKbCOSXpZDjXNYa4EhERkTOLrXBOtAAaOYuISHiLrXA+OXKu\n1IptEREJYzEVzsm2lnCurdeFSEREJHzFVDifukpYrUsjZxERCV+xFc42XcJTRETCX0yFsyXeiNkU\nR42mtUVEJIzFVDhDy+hZx5xFRCScxV44J8RTq2ltEREJYzEXzvaEeBqbPTQ1e0JdioiISJtiLpyT\nTp1OpdGziIiEqdgLZ//pVApnEREJTzEXzvYEnU4lIiLhLfbC+eS5ztW6hKeIiISpmAvnlKSWm18o\nnEVEJFyZOrLR8uXL2bZtG263m9tvv5233nqLvLw8UlNTAbj11lu54oorWu3z6KOPsn37dgwGA0uW\nLGHMmDFBL74zUk7d01nhLCIiYardcN60aRP79+8nNzeXiooKrrvuOi6++GJ+/OMfM2XKlDb32bJl\nC4cPHyY3N5cDBw6wZMkScnNzg158Z/jDWbeNFBGRMNVuOE+YMME/6k1OTsblcuHxnP0c4Y0bNzJt\n2jQAcnJyqKqqora2lqSkpCCUHJhTt42srmsMcSUiIiJta/eYs9FoxGazAbB69WomT56M0WjkT3/6\nEzfddBPz58+nvLy81T6lpaU4HA7/92lpaZSUlAS59M6JNxmxWUya1hYRkbDVoWPOAOvXr2f16tWs\nWrWKXbt2kZqayvDhw3nmmWf49a9/zYMPPnjGfX0+X7uv73DYMJmMHS2nQ5xOe5uPp6VYqa5rOuPz\n8jn1KDjUx8Cph4FTD4OjO/rYoXDesGEDK1as4Nlnn8Vut3PJJZf4n5s6dSoPPfRQq+0zMjIoLS31\nf19cXIzT6Tzre1RU1J9D2e1zOu2UlNS0+VyS1cTR4lqOn6jCZIy5BesddrYeSsepj4FTDwOnHgZH\nMPt4tpBvN5lqampYvnw5Tz/9tH919p133klBQQEAmzdvZvDgwa32mTRpEm+88QYAeXl5ZGRkhMXx\n5lOSE08dd9bUtoiIhJ92R85r166loqKCe+65x//Y9ddfzz333ENCQgI2m41ly5YBMH/+fJYtW8b4\n8eMZOXIks2fPxmAwsHTp0q77BJ3gsLec61xZ20RasjXE1YiIiLRm8HXkgHA3CPZ0y9mmHtZ9WMCL\nb+7nR9eN4vyhGUF932iiabDgUB8Dpx4GTj0MjrCZ1o5GaSdHzuXVOp1KRETCT0yG86lp7YoahbOI\niISfmA7n8pqGEFciIiJyupgM55QkMwaDRs4iIhKeYjKcjXFxpCZZFM4iIhKWYjKcAdKSW8LZ4/WG\nuhQREZFWYjace6Qk4PH6NHoWEZGwE8Ph3HLxkbIqLQoTEZHwErPh7ExNAKCkUuEsIiLhJWbD+dTI\nubTKFeJKREREWovdcNbIWUREwlTMhnOa3YLBAGUaOYuISJiJ2XA2GeNISTRTUavV2iIiEl5iNpyh\n5TKeFTVNhMmNuURERICYD2crbo+XWldzqEsRERHxi+1wTtLdqUREJPzEdDin2s2AwllERMJLTIdz\nmr3lXGctChMRkXAS0+GcevK+zhXVCmcREQkfMR3OjlPhrJGziIiEkdgOZy0IExGRMBTT4WwxG7FZ\nTFQqnEVEJIzEdDgDOJItlCucRUQkjCickyy4Gt00NLlDXYqIiAigcP58xbZGzyIiEiZiPpzTToaz\njjuLiEi4iPlwPnU6lY47i4hIuIj5cM5ITQCgqEL3dRYRkfAQ8+GcmWYDoKi8PsSViIiItIj5cE61\nWzDHxymcRUQkbMR8OMcZDGQ6bJyoqMfn84W6HBEREYUztExtNzV7qaxtCnUpIiIimDqy0fLly9m2\nbRtut5vbb7+d0aNHc9999+F2uzGZTDz++OM4nU7/9ps3b+buu+9m8ODBAAwZMoSf/OQnXfMJgiAr\nrWVR2Inyev/qbRERkVBpN5w3bdrE/v37yc3NpaKiguuuu46LLrqIWbNmMWPGDF544QV+97vfsXDh\nwlb7XXjhhTz55JNdVngwZTo+XxQ2vJ8jxNWIiEisazecJ0yYwJgxYwBITk7G5XKxdOlSLJaWEabD\n4SAvL69rq+xiWSdXbJ/QojAREQkD7Yaz0WjEZmsJr9WrVzN58mT/9x6Phz//+c/86Ec/Om2//Px8\nfvjDH1JVVcW8efOYNGnSWd/H4bBhMhk78xnOyOm0d2g7a+LJS3jWNXV4n1ihfgSH+hg49TBw6mFw\ndEcfO3TMGWD9+vWsXr2aVatWAS3BvHDhQi6++GIuueSSVtv279+fefPmcfXVV1NQUMBNN93EunXr\nMJvNZ3z9iorgjlqdTjslJTUd3j4pIZ4jJ2rOaZ9od649lLapj4FTDwOnHgZHMPt4tpDv0GrtDRs2\nsGLFClauXInd3vJi9913H/369WPevHmnbZ+ZmcmMGTMwGAxkZ2fTo0cPioqKOll+98hMS6C00oXb\n4w11KSIiEuPaDeeamhqWL1/O008/TWpqKgBr1qwhPj6eu+66q8191qxZw3PPPQdASUkJZWVlZGZm\nBrHs4Mty2PB4fZRVNYS6FBERiXHtTmuvXbuWiooK7rnnHv9jx44dIzk5mRtvvBGAnJwcHnroIebP\nn8+yZcuYOnUqCxYs4M0336S5uZmHHnrorFPa4SDzC4vCTn0tIiISCu2G83e+8x2+853vdOjFfvnL\nX/q/XrFiReerCoEsXWNbRETChK4QdpJ/5Ky7U4mISIgpnE/KcJy8SlhZXYgrERGRWKdwPskSb6RH\nipWjJXW6AYaIiISUwvkL+mXZqXU1U1HTGOpSREQkhimcv6BfZss53J+d0In6IiISOgrnL+ifpXAW\nEZHQUzh/QfbJcD5SpHAWEZHQUTh/QbLNTFqyhc9O1GhRmIiIhIzC+Uv6ZdqprmuisrYp1KWIiEiM\nUjh/Sb+TU9uHddxZRERCROH8JZ8vCqsOcSUiIhKrFM5f0i8rGYAjRbUhrkRERGKVwvlLUhLNpCaZ\nNXIWEZGQUTi3oX9WMpW1TVTV6kphIiLS/RTObcjOTALgsM53FhGREFA4t6H/yePOulKYiIiEgsK5\nDTqdSkREQknh3IbUJDPJiWZNa4uISEgonNtgMBjon2WnvLqRSi0KExGRbqZwPoOh2akA7D5cEeJK\nREQk1iicz2BEvzQAdn+mcBYRke6lcD6DvplJJFpN7DmicBYRke6lcD6DuJPHnUurGqhvcIe6HBER\niSEK57Pok9FyMZLCUl1nW0REuo/C+Sz6OFvC+WixwllERLqPwvks+p4cORconEVEpBspnM+iZ3oi\nCRYjn+SX4vZ4Q12OiIjECIXzWcSb4pg0qieVtU18tK8k1OWIiEiMUDi349IxPQHYdbA8xJWIiEis\nUDi3o48zCUu8kUMnqkNdioiIxAiFczvi4gz0y0ziWGkdDU0631lERLqeqSMbLV++nG3btuF2u7n9\n9tsZPXo0CxcuxOPx4HQ6efzxxzGbza32efTRR9m+fTsGg4ElS5YwZsyYLvkA3aF/z2T2Ha3i8Ika\nhmY7Ql2OiIhEuXZHzps2bWL//v3k5uby7LPP8uijj/Lkk09yww038Oc//5l+/fqxevXqVvts2bKF\nw4cPk5ubyyOPPMIjjzzSZR+gOwzslQzAoeO6haSIiHS9dsN5woQJPPHEEwAkJyfjcrnYvHkzV155\nJQBTpkxh48aNrfbZuHEj06ZNAyAnJ4eqqipqayP3XOH+PVvC+TMddxYRkW7QbjgbjUZsNhsAq1ev\nZvLkybhcLv80dnp6OiUlrU8zKi0txeH4fPo3LS3ttG0iiTPFSlJCPAePKZxFRKTrdeiYM8D69etZ\nvXo1q1atYvr06f7HfT5fu/t2ZBuHw4bJZOxoOR3idNqD9lpD+jn4aE8x8VYzqXZL0F433AWzh7FM\nfQycehg49TA4uqOPHQrnDRs2sGLFCp599lnsdjs2m42GhgasVitFRUVkZGS02j4jI4PS0lL/98XF\nxTidzrO+R0VFfSfKPzOn005JSfCOEQ/qmcxHe4pZv+kQl4/rHbTXDWfB7mGsUh8Dpx4GTj0MjmD2\n8Wwh3+60dk1NDcuXL+fpp58mNTUVgIkTJ/LGG28AsG7dOi677LJW+0yaNMn/fF5eHhkZGSQlJXX6\nA4SDC4a1/HGxZXdxiCsREZFo1+7Iee3atVRUVHDPPff4H/vpT3/KAw88QG5uLr169eKb3/wmAPPn\nz2fZsmWMHz+ekSNHMnv2bAwGA0uXLu26T9BNeqQkkNMrmT1HKqiuayI50dz+TiIiIp1g8HXkgHA3\nCPZ0S1dM4az7sIAX39zPjdOHMGV8n6C+djjSNFhwqI+BUw8Dpx4GR9hMa8vnLhjaMrX94R5NbYuI\nSNdROJ+DtGQrg/uksPdIJZW1jaEuR0REopTC+RxNGJaBD9iq0bOIiHQRhfM5On9oy2ljH+8vbWdL\nERGRzlE4nyOH3UK/LDv7CipxNeouVSIiEnwK504Ym5OOx+sj71B5qEsREZEopHDuhLGDegCw/YCm\ntkVEJPgUzp3QL8tOcqKZnQfK8IbHaeIiIhJFFM6dEGcwMGZgOtX1zWzKOxHqckREJMoonDvpmon9\nsJqN/OH1vew+XBHqckREJIoonDsp02Hjjm+Owufz8Zu/76S6rinUJYmISJRQOAdg9MB0vn3FIOoa\n3PzjvUOhLkdERKKEwjlA087vQ0qimQ/3FOPxekNdjoiIRAGFc4Di4gyMH+qk1tXM3iOVoS5HRESi\ngMI5CC4angnAvzYfCXElIiISDRTOQTC4Twoj+jvIO1TO7/+1W+c+i4hIQBTOQWAwGLjpqmH0cSbx\n7vbjbNylc59FRKTzFM5BkpGawD0zx2A2xbH6PwdoaNJNMUREpHMUzkGUlmzlqouyqapt4m9vH9D0\ntoiIdIrCOciuvqgfmY4E3v64kN++soumZk+oSxIRkQijcA4yi9nIkhvPZ0jfVLbtLeE3r+zS+c8i\nInJOFM5dwG4zs2D2OEYNTGPHgTL+vH4/rkYdgxYRkY5ROHcRkzGOH1w7kpQkM29/VMhPntvM0ZLa\nUJclIiIRQOHchZIS4rl/zvlMu6AP5dWN/CL3EypqGkNdloiIhDmFcxfrkZrADdOGMGvKICprm/jj\nG3vxaRW3iIichcK5m3z1wr4M7ZvKJ/mlvLntaKjLERGRMKZw7iYGg4Fbvzac5EQzf3lzP69vPkJ9\ngxaJiYjI6RTO3ahHSgJ3f3sM8cY4/vp2Pg+u2szxsrpQlyUiImFG4dzNBvRM5sFbJvCVC/pSXt3I\nM2s+5ZP8Up0LLSIifqZQFxCLevVIZPaVg9h3tJLDJ2p4cvUO0pMtXDtpAJeMzCTeZDxtH6/Xx4tv\n7sft8fKNywaSkmgOQeUiItIdFM4hYjAYmDVlELlv7seeaGZ/QSW//9cenn99LylJZlKTzNx81TCy\nM+2s31rAX9bv59Qa79LqBr59eQ7ZmfaQfgYREekaBl8HzuvZt28fc+fO5ZZbbmHOnDncddddVFRU\nAFBZWcm4ceN4+OGH/du//PLLPPHEE2RnZwMwceJE7rjjjrO+R0lJTSCf4zROpz3or9mVyqsb+OfG\nwxworOJI8ecXK0mwGHE1tn197q9N7M/1kwd2WU2R1sNwpT4GTj0MnHoYHMHso9N55gFWuyPn+vp6\nHn74YS655BL/Y08++aT/6/vuu4+ZM2eett+MGTNYtGjRudYas9KSrdz41aH+73ccKOWFf++jsdmL\nMS6O/ll2hvdzkJlm45k1eTS5vbz2wWdY4uOYOKonDrslhNWLiEgwtRvOZrOZlStXsnLlytOeO3jw\nIDU1NYwZM6ZLiotlY3J6MCanR5vPrVhwBQcKq3jkj9t46T8Hefndg/zXV4YwdXyfbq5SRES6Qrur\ntU0mE1artc3nnn/+eebMmdPmc1u2bOHWW2/l5ptv5tNPPw2sSjlNTu8UFn73PL5x6QASrfH8ad0+\n3ttxHID6huYQVyciIoHo0DFngKeeegqHw+EP46amJr71rW/x6quvnrbtgQMHKCgo4IorruDjjz/m\nwQcfbHO7L3K7PZjaWKUs7TsKCeOvAAAXIUlEQVR8vJr7fvMeda5mBvZJJb+gksvP68Od3xmHz+vD\natG6PxGRSNLp39offvjhGaezc3JyyMnJAeC8886jvLwcj8eD0Xjm8K2oqO9sKW2KpcUPNpOBe2aO\n5fG/fEx+QSUA//n4KP/5uOUyoVddmM2sqYPO+XVjqYddSX0MnHoYOPUwOLprQVinL0Kyc+dOhg0b\n1uZzK1eu5LXXXgNaVnqnpaWdNZglcAN6JvPf37uQr03sz+L/Gs+AnskY4wwYDPD6liNs3VMc6hJF\nRKSD2h0579q1i8cee4zCwkJMJhNvvPEGTz31FCUlJf5TpU654447+O1vf8u1117Lvffey4svvojb\n7eaRRx7psg8gn3OmJvhPrVr8X+Opb2imqq6JR/+0jd+8sgubxcT4oU4SrSbKqxv51hU5ZKQmhLhq\nERH5sg4fc+5qsX6ec1fKL6zitQ8+4/CJGqrqmvyP98uys+iG87Ca2/4bTT0MDvUxcOph4NTD4Aib\n85wl8g3qncI9M8fianTzh9f3kJ5ipaTCxda9JTz+l4+581tjSEqIx2TUpdZFRMKBwjmGJFhM/PAb\nowBwe7ywJo+te0v48a/fJ9kWz53fHkNOrxS8Xh8f7inG5T6OweulZ3oiQ/qmhrh6EZHYoXCOUSZj\nHLOvHMy2fSX4fFBd38yqf+4mK83G/qNV1LqaW2378x9NxG7TzTZERLqD5jFjWFqylftvvID/ufVC\nLhqRyfGyej7eX0qtq5n+WXYW3zyBnF7JuD1e7n7yPV7ZcJBmd8utLesamln9zgGOltS28y4iInKu\nNHKOcQN7JQNw4/ShjM1JJ6d3CuZ4I4lWEz2zUujjSGDRig+oa3Cz5v3P2HGgjK9N7M87nxSy62A5\nazcd5rzBPZg6vg+DeqdgMeuUORGRQGm1tpzRqR5W1Tbi9vh4ZcNB3t91otU2qUlmKmtbVoDbbfF8\n89IBYDAwtG8qvXokhqLsVpqaPXi8PhJCeJU0/V8MnHoYOPUwOLRaW8JGSlLLHa9u/doIpozvw65D\nZXg8PiaP7UV6ipUdB8rYeaCM/2w/xh/X7QMg3hTHfXPG0z8rOWR1Hy+r48nVOyipbCDeFIfVbOSu\nb49hQM/Q1XSKq9FNQXEtg/ukYDAYQl2OiIQZhbOck4G9kv1T4aeMyUlnTE46I/o7eHnDQbIzktiU\nV8T//H4r6clWstJtjBqQxrQL+mCMO/Myh+JKF7lv7mfiqCyamr2UVLr42qT+xHUgvPYVVPLejuM4\nU61s3VtCVV0T1SfP6TbGGbCYjVTVNfGbv+/klquHM3JAWmCNCIDP5+PXL+9k9+EKvnJBX0b0dzCw\nV7IW3ImIn6a15YwC6eH7O4/zx3V7AWhqbllElmAxMmlUT751eU6rY9Nen49te0v4w7/2UN/obvU6\nw/s5uPL8Puw8WMbxsnpu//rI0+5d/cn+Un7zyq6W08NOSrCYGNwnhYmjspgwLAOAh373IQXFLQvY\nrps8kHGDerBldxFXXZRNojW+U5+zI77YR7fHy1/fymf9tqMYgFM/fD3TbQzNdlBS6SKnVzLfvGxg\nl9UTiZxOO0XF1RwtriXRGk9lXSM5vVJCXRYAR4pq+NO6fUwancXEUVk0u33YrOE37tHvxODormlt\nhbOcUaA99Hi9GAwGauub+ds7+WzPL6PW1UxGagI3fGUIY3LS2ZR3gmdebbmlqMVsZFjfVHYdKqe3\nM5EjRaevBO+ZbmP+rLH4fPDejuN8vL+UoyW1mOPj+P41I/ABzlRrm9Pp+woqefWDz9hfUEmT+/Mg\nH9grmf/3nXEkWEwcOl5NaVUDFwx1Bm26+Yt9fGXDQda8/xkZqQnc/o2RvPyfA+R9VnHaPnOmD+H8\noRk8//oeXI1u+mXZeX/nCcbmpDNr6qBWo+ziinosZhMpidE38vZ4vVTVNmGxWVj59x3sOFAGgAG4\n+ephTBqdddbZmK5W3+Bm8dMbW516mGAx8fCtF5KW3PatdkMlnH4nHi2pZX9BJecPzcASb8QcHxcW\nh3f2FVTy17fzuebifuw7Wkl2hp1LRmW12kbhHKBw+o8YqYLdw2a3h79vOMQbW47g80F6spWquibc\nHi8Ou4W7vjWGfll2vF4fcXEGXI1u8g6V8+72Y4wb3IPiChfrPiw47XUTLCbmzxzLoD4dG0nlF1bx\n2AsfYTQa8Hp9uD0+UhLNpNotHD7R8nm/fUUOF4/IbPUL1uv18fH+UqrrGhnWz0GiNZ7kk4Ho8Xox\nxsXhanSz+dMizhviJMFsZN/RSj7IK8Iab6Sk0kXeoXLSky389/cu8o+uvD4fh45XYzYZMRjgsRc+\noq7BfXrhJyUlxNO/p52aumYqahqorm/GYbfwP7de2OYMgM/nY9ehcg4dr2Zk/zRyenf/iLO+wU2C\nxdihX8D5hVW8vvkI8aY4Ckvqznq6Xt+MJO781mh6pHT/NeLzj1bxm1d2UlnbhMNuoaKmsdXz2RlJ\nOFMTmHZBH4ZmOyitctHY5CEzzcbKVz/FajZy81XDiIvrnlAKxe/EZreHLbuLuWBYSwg3NLk5fKKG\n3/4jz3/YCeD6yQOZMr53l85gtcfr8/HQqi0cLalr9fgtVw+jqdnDyAFp9ExPVDgHSuEcuK7q4dHi\nWv72zgGOFNdgjTcyc8ogxg9xtrufz+fj31uPsvNgGYlWE/YEM2MGpZOVZsN5jjfwKK9uINEaj8lk\n4MU389m6t5iq2iYG90lh/9EqoGV0dsX43owf4uREWT2bPy0iv7DK/xopSWb+a9oQ3thyhKOldXz7\n8hx2Hizzj+7iDAa8X/rxSk408+NZY8nOPPMPZVF5PX95cz8nyuq58vw+uD1efMCk0T15b8cx/v7u\nIbw+H2ZTHKl2C8UVLqBltfyN04eSmWYjLs6AI8nC2k2H2fTpCcqrPw+OjNQEsjOTuGBYBhcOzwTg\n+df3cLSkjqx0G7sOlnHj9KFYzEaq65oY3s/hXxTYUQcKq9iyu5hrLunHX9/O54NdJ7h4RCY3fGUI\nhSW1JCbE08eZdNp+2/NL+fXLO/F4P+/bwF7J9MmwM6q/g3GDe1Be00hNXRP/3lrAlt3F9M+yM6hP\nCgcKq5k4Koup43t3ySis2e3lnY8L8Xh99HYm8vQ/8qhvdJOebOXh71/I0eI6+mQk8qu/7WD/0UpO\n/dMbaLkpTXGl67TXvHR0T2ZNHYTVbKSguJaGJg92W9u9OaWx2cOBwiqy0mznNDoPxe/E3Lf288aW\nAiaNzqJ3jyReee+g/zDXRSMyKSqv57MTn9e09JYJ9Ms6889GV/F4vTz/+l427DjOyP4OSiobTvv3\nMsYZmHvdKKZPHKhwDoTCOXCx1sNmt5d4Uxzrthxh/9EqCoprT/sBHZuTjsNu4Z1Pjp31tfpmJGE1\nG+mbkcQlY3tTWVnv/yPCHB/YueCllS6aPV6y0mwYDAY8Xi8vrs/n3R3H/BeJAfzHtBMsJob2TeW8\nIT3YtreEA4VV/pH5rCmDyEqz8eRLO874fimJZr552QAuG9OrQ6O8A8eqeOT5bWfdxmSM47ZrRzBh\nWAa+k2sO6hvd/GX9fnw+HzdfNYyDx6oZMyid0QPTz/h/ceWrn7Ixr/XpfZNGZxFvjMPV5MFmNXHh\nsAysZhN9M5NaLS7MP1rF7/61m4YmD87UBG6+aih2m5m/v3uQ8UOdjOjnYNU/d9Pk9pKSZGbDjuM0\nNnla9ffGrw7lsrE925xar6hppKi8nj/9ex+lVS5G9EvjcFENFTWNZDgSMABFJ/+wMsYZWv1B8t0r\nB3PpmJ6YjAbiTS3/X4or6tm6t4T3dhznRHk9xjgDl4zK4vJxvfzH390eL6++/5n//57dZsZiNpKa\nZKZvb0enf573HK4gLcVKQ6ObD3adYNSANEYNTG9zW5/Ph88Hx8rq+O/ffdjqcyXb4jl/aAYj+qcx\nfkgPDAYDW3YXseIfeQD06pFI34wktu0tZmi2g9u/PpKkhHjcHi8ej6/d6yg0u700NntISmg9Avf5\nfBw8Xk3PtESa3R5OlNfT7PFysLCa7QfKqG9opqjCRb8sO/NnjSUpIR6Px8fuw+X8+8MCejuTeHf7\nMYb2TeV/516qcA5ErAVLV4j1Hta6mnl3+zGamj1kOmz072mnZ3rLudvNbi8rX/uUeKOB6ROyMRoN\nPPL8NlKTzDxw8wWtpue6q49HimpY8/5nfLSvxP/Y1yf1Z8bF/Vr9QeDz+dh7pJInX9pBwxfCZvbU\nQSRYTOR9Vs6Hu4uZMr43ZpOx5TAEMCw7lTE5PUhNMmOONzImJ/20m6XkH63imVfzKK1qwGo20tDk\nIdkWzwM3X8AHO0/wynuHALDEG2lq9jB2UA8SE0y8v/PzgP3W5QO55pL+rV73TD1savbwyoZDFJTU\nMvOKHJ597dPTpiVP6eNMYuaUHCprGnl3xzEOFFaftk1asoXy6kaMcQbGDW75Y+aLzw3pk8rOg2Vk\npdm46aph9M048wj3i04dqqlvcHPgWBUj+jtodnv594cF/svlDuiZTHKimbc/Okp1fcsx7OREM9dP\nHkhqkoXfvLKTpmYvBmDkgDT2FlTS7G75fnROOn0zkqioaeSDL12LACA92ULfrGSKyupYMPs8vF4f\nyYlm4k3tH69/66Oj/GndPpJt8cSbjJRVNwAtZ2kkWEzsOljG8P5p/ODaEZiMcf51FadMn9CXA8eq\n8Hph3vWjT1vQCS1Tyrlv5vPvrS2HrU79sTJuUA+G9E3lH+8dwuP1MWtKDpeN7YXlS3/gNru9bP60\niFfeO0h9g5sbvzqU3Z9VUFxRj6vJQ06vZN755BgJFhONTZ7TZrSMcQbGDerB964ZfsZrItS6mjEZ\nDQH9kfNlCmfpFPXw3FTVNmI1m0776767++j2ePntK7vIzrTzjUsHnHG7ytpG3t95nP1Hqxg/xMll\nY3piMBjw+XzUN7r9f2AUVdTz1Es7OVbaOvQyUhO4cEQGX5/U8h5/33CQf206AsDFIzK57doRHC+r\nx2Y1kXpyWjzvUDk1riZ6pSfy+3/t8U9pmowGpp3fl74ZSVw0IvO0EXpHe+hqdLM9vxSnIwGbxcQH\nu06wduNhEiymVmcCnAq0qy/KZmi2g6de2sHH+0sxGeOw2+L9x4+TEuI5f6iTAT2TmTgqC5MxDq/P\n16HT+zpr75EKfrV6B03NHuJNcf5pYJMxju9OG8z5Q5wkJ5o5UlTD+ztP8M4nha1mTKxmI9+dNpii\nchf7CipbHYr5IqvZyHWXDSQuzkCGI4HRXxoJ+3w+dh4s46mXWh9mGNInhWZPyzqJL5o+oS+9erT8\nu0LLYZ1brxl+2oKqM/H5fGzZXYwl3siogWk89sJHHDjW8h5mU5x/EafFbOTS0T1JTTJz+EQNta5m\nCoprz7pO44ssZiMj+6eRmZZAss3MRSMySbaZO3zsX8ecA6RgCZx6GBzR0MfGJg8HjlXR2OShsraR\n3Ucq2bqnGIAMRwI+n4+SygYyHAnMnjqY0TlpHVpFffhEDcdK6xianXrW46eB9LC+oRmbNZ5te4s5\nXFSD3WZmbE46GQ6bfxtXo5sDhVVkZ9lJtpkpLK0jztBy/fkvj9K6Q3GlC1eDm+TElmn2PUcquPWa\n4QzNdpy2bWOTh4ZmD/lHKzl4rJrh/R2MGtA6aI+V1pGaauPFdXvYc7iCzDQbB49V4WpsmTmJMxiY\nNSWH3s4kBvZKxuvz8be383l3+3EAbpw+hP98cozBfVOZNWUQcXGwbW8JCRYT/bLs3P/MplbheNVF\n2UwclXXWY+ftqW9ws35rAW6vlynn9aGqrpF3PznG9gNlrRbfGYAeqVbGD3Ey7fy+7DlSQd6hckYP\nTGf8ECf/+aSQksoGpk3oQ0ZqAl6fL6AV/grnAEXDL8RQUw+DI1r76Dp5jHjz7iKa3V4uHJ7BzVcN\n65JLpUZrD7vTl3tYXOliw/ZjFJbUsT2/lLaCoFePRK6fPLDdBZtHS2r5z8fHSEww0TM9kQnDMrps\nFbrb42V7fhkFxTWMH+IkM83WrX9AKZwDpB/mwKmHwRHtfWx2e6l1NZOaZO6yc1WjvYfd4Ww9rKhp\n5MPdRVTVN/HBrhPEGQxMHd+bKef1CcsLqoSSrq0tIhEh3hTX5iIfiRwOu4XpF2YDMPOKQSGuRkD3\ncxYREQk7CmcREZEwo3AWEREJMwpnERGRMKNwFhERCTMKZxERkTCjcBYREQkzCmcREZEwo3AWEREJ\nMwpnERGRMKNwFhERCTMKZxERkTATNnelEhERkRYaOYuIiIQZhbOIiEiYUTiLiIiEGYWziIhImFE4\ni4iIhBmFs4iISJgxhbqArvDoo4+yfft2DAYDS5YsYcyYMaEuKazt27ePuXPncssttzBnzhyOHz/O\nwoUL8Xg8OJ1OHn/8ccxmM2vWrOEPf/gDcXFxzJo1i5kzZ4a69LCxfPlytm3bhtvt5vbbb2f06NHq\n4TlwuVwsXryYsrIyGhsbmTt3LsOGDVMPO6GhoYGvfe1rzJ07l0suuUQ9PEebN2/m7rvvZvDgwQAM\nGTKE73//+93fR1+U2bx5s+8HP/iBz+fz+fLz832zZs0KcUXhra6uzjdnzhzfAw884PvjH//o8/l8\nvsWLF/vWrl3r8/l8vp///Oe+F154wVdXV+ebPn26r7q62udyuXzXXHONr6KiIpSlh42NGzf6vv/9\n7/t8Pp+vvLzcd/nll6uH5+if//yn75lnnvH5fD7f0aNHfdOnT1cPO+kXv/iF7/rrr/e99NJL6mEn\nbNq0yXfnnXe2eiwUfYy6ae2NGzcybdo0AHJycqiqqqK2tjbEVYUvs9nMypUrycjI8D+2efNmrrzy\nSgCmTJnCxo0b2b59O6NHj8Zut2O1Whk/fjwfffRRqMoOKxMmTOCJJ54AIDk5GZfLpR6eoxkzZnDb\nbbcBcPz4cTIzM9XDTjhw4AD5+flcccUVgH6WgyUUfYy6cC4tLcXhcPi/T0tLo6SkJIQVhTeTyYTV\nam31mMvlwmw2A5Cenk5JSQmlpaWkpaX5t1FfP2c0GrHZbACsXr2ayZMnq4edNHv2bBYsWMCSJUvU\nw0547LHHWLx4sf979bBz8vPz+eEPf8h3v/td3n///ZD0MSqPOX+RT1cnDciZ+qe+nm79+vWsXr2a\nVatWMX36dP/j6mHHvfjii+zevZt77723VX/Uw/a98sorjBs3jr59+7b5vHrYMf3792fevHlcffXV\nFBQUcNNNN+HxePzPd1cfoy6cMzIyKC0t9X9fXFyM0+kMYUWRx2az0dDQgNVqpaioiIyMjDb7Om7c\nuBBWGV42bNjAihUrePbZZ7Hb7erhOdq1axfp6en07NmT4cOH4/F4SExMVA/PwTvvvENBQQHvvPMO\nJ06cwGw26/9hJ2RmZjJjxgwAsrOz6dGjBzt37uz2PkbdtPakSZN44403AMjLyyMjI4OkpKQQVxVZ\nJk6c6O/hunXruOyyyxg7diw7d+6kurqauro6PvroIy644IIQVxoeampqWL58OU8//TSpqamAeniu\ntm7dyqpVq4CWQ1P19fXq4Tn61a9+xUsvvcRf//pXZs6cydy5c9XDTlizZg3PPfccACUlJZSVlXH9\n9dd3ex+j8q5UP/vZz9i6dSsGg4GlS5cybNiwUJcUtnbt2sVjjz1GYWEhJpOJzMxMfvazn7F48WIa\nGxvp1asXy5YtIz4+ntdff53nnnsOg8HAnDlz+PrXvx7q8sNCbm4uTz31FAMGDPA/9tOf/pQHHnhA\nPeyghoYG7r//fo4fP05DQwPz5s1j1KhRLFq0SD3shKeeeorevXtz6aWXqofnqLa2lgULFlBdXU1z\nczPz5s1j+PDh3d7HqAxnERGRSBZ109oiIiKRTuEsIiISZhTOIiIiYUbhLCIiEmYUziIiImFG4Swi\nIhJmFM4iIiJhRuEsIiISZv4/egnf06qNYtUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffa0f2e1eb8>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "boy_iter.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction using the saved weights/learned weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "colab_type": "code",
    "id": "2JLs2XW4PamA",
    "outputId": "94de3430-8edd-4116-efd0-2d168a98bc7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zrtol\n",
      "\n",
      "\n",
      "Caadkom\n",
      "\n",
      "\n",
      "Ttren\n",
      "\n",
      "\n",
      "Aadon\n",
      "\n",
      "\n",
      "Tohein\n",
      "\n",
      "\n",
      "Aerqi\n",
      "\n",
      "\n",
      "Randin\n",
      "\n",
      "\n",
      "Brreb\n",
      "\n",
      "\n",
      "Bickieuleme\n",
      "\n",
      "\n",
      "Rred\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for Prediction\n",
    "seed = 4\n",
    "for name in range(10):\n",
    "  # Sample indices and print them\n",
    "  sampled_indices = sample(boy_params[0], char_to_ix, seed)\n",
    "  print_sample(sampled_indices, ix_to_char)\n",
    "  seed += 1  # To get the same result for grading purposed, increment the seed by one. \n",
    "  print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QmGV1NgRQz64"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BabyNames.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
