{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pickle(path):\n",
    "    objects = []\n",
    "    with (open(path, \"rb\")) as openfile:\n",
    "        while True:\n",
    "            try:\n",
    "                objects.append(pickle.load(openfile))\n",
    "            except EOFError:\n",
    "                break\n",
    "    return objects\n",
    "\n",
    "def get_features_targets(path_features,path_targets):\n",
    "    features = read_pickle(path_features)\n",
    "    targets = read_pickle(path_targets)\n",
    "    return (features[0],targets[0])\n",
    "\n",
    "def remove_nan_inf(array, change_value=0):\n",
    "    if np.isnan(array).any():\n",
    "        pos = np.isnan(array)\n",
    "        array[pos] = change_value\n",
    "    if np.isinf(array).any():\n",
    "        pos = np.isinf(array)\n",
    "        array[pos] = change_value\n",
    "    return array\n",
    "\n",
    "def check_nan_inf(array): \n",
    "    return (np.isnan(array).any() or np.isinf(array).any())\n",
    "\n",
    "def get_shit(loc_features, loc_targets, name):\n",
    "    features_, targets_ = get_features_targets(loc_features, loc_targets)\n",
    "    print( name+'...')\n",
    "    print('Nan Before', check_nan_inf(features_))\n",
    "    features_ = remove_nan_inf(features_)\n",
    "    print('Nan After', check_nan_inf(features_))\n",
    "    print(name + 'Shape:', features_.shape)\n",
    "    return features_, targets_['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(arr):\n",
    "    dic = {}\n",
    "    # Tf-idf normalized cosine similarity\n",
    "    tf_idf_c = arr[:,41]\n",
    "    print('Tf_idf shape:',tf_idf_c.shape)\n",
    "    dic['tf_idf_c'] = tf_idf_c\n",
    "    \n",
    "    # Headline body similarity\n",
    "    head_body_sim = arr[:,142]\n",
    "    dic['Head_Body_Sim'] = head_body_sim\n",
    "    \n",
    "    # Headline body sentiments\n",
    "    head_senti = arr[:, 143:147]\n",
    "    body_senti = arr[:, 147:151]\n",
    "    print('Headline sentiments shape:{}\\n Body sentiments shape: {}\\n'\\\n",
    "          .format(head_senti.shape, body_senti.shape))\n",
    "    \n",
    "    dic['Head_compound'] = head_senti[:,0]\n",
    "    dic['Head_neg'] = head_senti[:,1]\n",
    "    dic['Head_neu'] = head_senti[:,2]\n",
    "    dic['Head_pos'] = head_senti[:,3]\n",
    "    \n",
    "    dic['Body_compound'] = body_senti[:,0]\n",
    "    dic['Body_neg'] = body_senti[:,1]\n",
    "    dic['Body_neu'] = body_senti[:,2]\n",
    "    dic['Body_pos'] = body_senti[:,3]\n",
    "    \n",
    "    # Readibility features\n",
    "    read_f = arr[:,151:162]\n",
    "    print('Readibility features shape:',read_f.shape)\n",
    "    keys = ['flesch_reading_ease', 'smog_index', 'flesch_kincaid_grade',\n",
    "        'coleman_liau_index', 'automated_readability_index', \n",
    "        'dale_chall_readability_score', 'difficult_words', 'linsear_write_formula',\n",
    "        'gunning_fog', 'i_me_myself', 'punct']\n",
    "    t_dic = {keys[i]:read_f[:,i] for i in range(len(keys))}\n",
    "    dic.update(t_dic)\n",
    "    df = pd.DataFrame(dic)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# For count and other features\n",
    "\n",
    "def get_count_wordvec(arr):\n",
    "    c_f = arr[:, :41]\n",
    "    print('Count features shape', c_f.shape)\n",
    "    word_vec_head = arr[:,42:92]\n",
    "    word_vec_body = arr[:,92:142]\n",
    "    print('Word_vec shape')\n",
    "    print('Head:\\t{} Body:\\t{}'.format(word_vec_head.shape,word_vec_body.shape))\n",
    "    return c_f, word_vec_head, word_vec_body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "(2232, 163)\n"
     ]
    }
   ],
   "source": [
    "features_scrapped,targets_scrapped = get_features_targets\\\n",
    "('datasets/generated_feature.pkl','datasets/generated_feature_targets.pkl')\n",
    "X_s = features_scrapped[:2232]\n",
    "y_s = targets_scrapped['target'][:2232]\n",
    "print(check_nan_inf(X_s))\n",
    "X_k =remove_nan_inf(X_s)\n",
    "print(check_nan_inf(X_s))\n",
    "print(X_s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================Count Features=========================\n",
      "Count features shape: (2232, 41)\n",
      "First element\n",
      "[  7.           7.           1.           6.           6.\n",
      "   1.           5.           5.           1.         312.\n",
      " 223.           0.71474359 311.         303.           0.97427653\n",
      " 310.         310.           1.           5.           0.71428571\n",
      "   0.           0.           0.           0.           1.\n",
      "  29.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.        ]\n",
      "=========================Tf-idf similarity=========================\n",
      "Shape: (2232,)\n",
      "First element\n",
      " [0.11833917 0.00697112 0.07370369 0.26053153 0.29439177 0.22756415\n",
      " 0.14593261 0.02041761 0.07684427 0.09184856]\n",
      "=========================Word to vec=========================\n",
      "Head\t\tBody\t\tSimilarity\n",
      "(2232, 50)\t(2232, 50)\t(2232,)\n",
      "\n",
      "[ 8.20541092e-02  1.57316458e-02  3.32752287e-03 -2.73157156e-02\n",
      "  6.92358593e-02  1.54418886e-02 -9.51810098e-02 -2.11282552e-02\n",
      " -3.34680330e-02 -1.48440022e-02  1.60808232e-02 -1.02009090e-02\n",
      " -8.51492036e-02 -3.51991562e-02  1.20794560e-01  6.94927995e-02\n",
      " -2.36653207e-05 -6.11756069e-02 -9.28155826e-02 -8.04015339e-02\n",
      "  4.23850759e-02 -1.09585746e-02  4.18712611e-02 -2.76015568e-02\n",
      "  2.88649683e-02 -3.95235294e-01 -8.00358495e-02  2.44427635e-02\n",
      "  2.91684513e-02  7.71634576e-03  8.56298938e-01  2.42149117e-02\n",
      " -1.80098315e-02 -8.75999226e-02  9.55295437e-03 -6.00399245e-02\n",
      "  2.06553267e-03  1.96929935e-02  9.86927451e-03 -5.13428079e-02\n",
      " -8.83685991e-02  1.13804710e-02  2.21756569e-02  2.31287652e-02\n",
      " -2.42139778e-02  6.93036682e-03 -1.30253015e-02  2.63811554e-02\n",
      "  1.44898552e-02 -2.39061703e-02]\n",
      "[0.80428227 0.97154232 0.96889223 0.91427951 0.93043182]\n",
      "=========================Head body sentiments=========================\n",
      "Shape\n",
      "(2232, 4) (2232, 4)\n",
      "[-0.8238  0.58    0.304   0.116 ]\n",
      "[-0.11927586  0.11724138  0.806       0.07672414]\n",
      "=========================Readibilty features=========================\n",
      "(2232, 12)\n",
      "[ 63.8         11.1          8.3         13.34        11.6\n",
      "   7.75       107.           8.28571429  16.79         3.\n",
      "  51.          56.45614035]\n"
     ]
    }
   ],
   "source": [
    "# Count features\n",
    "cf = X_s[:,:41]\n",
    "print('====='*5+'Count Features'+'====='*5)\n",
    "print('Count features shape:',cf.shape)\n",
    "print('First element')\n",
    "print(cf[0])\n",
    "\n",
    "# Tf-idf normalized cosine similarity\n",
    "print('====='*5+'Tf-idf similarity'+'====='*5)\n",
    "tf_idf_c = X_s[:,41]\n",
    "print('Shape:',tf_idf_c.shape)\n",
    "print('First element\\n',tf_idf_c[:10])\n",
    "\n",
    "# Word to vec\n",
    "print('====='*5+'Word to vec'+'====='*5)\n",
    "word_vec_head = X_s[:,42:92]\n",
    "word_vec_body = X_s[:,92:142]\n",
    "head_body_sim = X_s[:,142]\n",
    "print('Head', 'Body', 'Similarity', sep = '\\t\\t')\n",
    "print(word_vec_head.shape,word_vec_body.shape, head_body_sim.shape,sep = '\\t'); print()\n",
    "print(word_vec_body[1], head_body_sim[:5],sep ='\\n')\n",
    "\n",
    "# Word to vec\n",
    "print('====='*5+'Head body sentiments'+'====='*5)\n",
    "\n",
    "head_senti = X_s[:, 143:147]\n",
    "body_senti = X_s[:, 147:151]\n",
    "print('Shape')\n",
    "print(head_senti.shape, body_senti.shape)\n",
    "print(head_senti[0], body_senti[0], sep = '\\n')\n",
    "\n",
    "# Readibility features\n",
    "print('====='*5+'Readibilty features'+'====='*5)\n",
    "read_f = X_s[:,151:]\n",
    "print(read_f.shape)\n",
    "print(read_f[0])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tf_idf shape: (2232,)\n",
      "Headline sentiments shape:(2232, 4)\n",
      " Body sentiments shape: (2232, 4)\n",
      "\n",
      "Readibility features shape: (2232, 11)\n",
      "Index(['tf_idf_c', 'Head_Body_Sim', 'Head_compound', 'Head_neg', 'Head_neu',\n",
      "       'Head_pos', 'Body_compound', 'Body_neg', 'Body_neu', 'Body_pos',\n",
      "       'flesch_reading_ease', 'smog_index', 'flesch_kincaid_grade',\n",
      "       'coleman_liau_index', 'automated_readability_index',\n",
      "       'dale_chall_readability_score', 'difficult_words',\n",
      "       'linsear_write_formula', 'gunning_fog', 'i_me_myself', 'punct'],\n",
      "      dtype='object')\n",
      "==============================Tf_idf similarity=========================\n",
      "0    0.118339\n",
      "1    0.006971\n",
      "2    0.073704\n",
      "3    0.260532\n",
      "4    0.294392\n",
      "5    0.227564\n",
      "6    0.145933\n",
      "7    0.020418\n",
      "8    0.076844\n",
      "9    0.091849\n",
      "Name: tf_idf_c, dtype: float64\n",
      "[0.11833917 0.00697112 0.07370369 0.26053153 0.29439177 0.22756415\n",
      " 0.14593261 0.02041761 0.07684427 0.09184856]\n",
      "==============================Head Body similarity=========================\n",
      "0    0.804282\n",
      "1    0.971542\n",
      "2    0.968892\n",
      "3    0.914280\n",
      "4    0.930432\n",
      "5    0.983159\n",
      "6    0.863771\n",
      "7    0.895777\n",
      "8    0.961186\n",
      "9    0.829358\n",
      "Name: Head_Body_Sim, dtype: float64\n",
      "[0.80428227 0.97154232 0.96889223 0.91427951 0.93043182 0.9831592\n",
      " 0.86377075 0.8957768  0.96118585 0.82935807]\n",
      "==============================Sentiments=========================\n",
      "0   -0.8238\n",
      "1   -0.4215\n",
      "2    0.0000\n",
      "3    0.0000\n",
      "4   -0.5994\n",
      "5    0.0000\n",
      "6    0.0000\n",
      "7    0.0772\n",
      "8   -0.1779\n",
      "9    0.0000\n",
      "Name: Head_compound, dtype: float64\n",
      "0    0.580\n",
      "1    0.201\n",
      "2    0.000\n",
      "3    0.000\n",
      "4    0.438\n",
      "5    0.000\n",
      "6    0.000\n",
      "7    0.000\n",
      "8    0.210\n",
      "9    0.000\n",
      "Name: Head_neg, dtype: float64\n",
      "0    0.304\n",
      "1    0.714\n",
      "2    1.000\n",
      "3    1.000\n",
      "4    0.562\n",
      "5    1.000\n",
      "6    1.000\n",
      "7    0.698\n",
      "8    0.564\n",
      "9    1.000\n",
      "Name: Head_neu, dtype: float64\n",
      "0    0.116\n",
      "1    0.084\n",
      "2    0.000\n",
      "3    0.000\n",
      "4    0.000\n",
      "5    0.000\n",
      "6    0.000\n",
      "7    0.302\n",
      "8    0.226\n",
      "9    0.000\n",
      "Name: Head_pos, dtype: float64\n",
      "[[-0.8238  0.58    0.304   0.116 ]\n",
      " [-0.4215  0.201   0.714   0.084 ]\n",
      " [ 0.      0.      1.      0.    ]\n",
      " [ 0.      0.      1.      0.    ]\n",
      " [-0.5994  0.438   0.562   0.    ]\n",
      " [ 0.      0.      1.      0.    ]\n",
      " [ 0.      0.      1.      0.    ]\n",
      " [ 0.0772  0.      0.698   0.302 ]\n",
      " [-0.1779  0.21    0.564   0.226 ]\n",
      " [ 0.      0.      1.      0.    ]]\n",
      "==============================Article body=========================\n",
      "0   -0.119276\n",
      "1    0.447000\n",
      "2    0.045808\n",
      "3   -0.030663\n",
      "4   -0.159617\n",
      "5    0.002577\n",
      "6    0.277786\n",
      "7   -0.032550\n",
      "8    0.095175\n",
      "9   -0.987500\n",
      "Name: Body_compound, dtype: float64\n",
      "0    0.117241\n",
      "1    0.047333\n",
      "2    0.044583\n",
      "3    0.097875\n",
      "4    0.121278\n",
      "5    0.062000\n",
      "6    0.054357\n",
      "7    0.085200\n",
      "8    0.054583\n",
      "9    0.156000\n",
      "Name: Body_neg, dtype: float64\n",
      "0    0.806000\n",
      "1    0.826000\n",
      "2    0.685500\n",
      "3    0.748500\n",
      "4    0.807167\n",
      "5    0.863136\n",
      "6    0.796786\n",
      "7    0.855400\n",
      "8    0.841333\n",
      "9    0.741000\n",
      "Name: Body_neu, dtype: float64\n",
      "0    0.076724\n",
      "1    0.126667\n",
      "2    0.269833\n",
      "3    0.153750\n",
      "4    0.071556\n",
      "5    0.074864\n",
      "6    0.148786\n",
      "7    0.059500\n",
      "8    0.104250\n",
      "9    0.102000\n",
      "Name: Body_pos, dtype: float64\n",
      "[[-0.11927586  0.11724138  0.806       0.07672414]\n",
      " [ 0.447       0.04733333  0.826       0.12666667]\n",
      " [ 0.04580833  0.04458333  0.6855      0.26983333]\n",
      " [-0.0306625   0.097875    0.7485      0.15375   ]\n",
      " [-0.15961667  0.12127778  0.80716667  0.07155556]\n",
      " [ 0.00257727  0.062       0.86313636  0.07486364]\n",
      " [ 0.27778571  0.05435714  0.79678571  0.14878571]\n",
      " [-0.03255     0.0852      0.8554      0.0595    ]\n",
      " [ 0.095175    0.05458333  0.84133333  0.10425   ]\n",
      " [-0.9875      0.156       0.741       0.102     ]]\n",
      "==============================Reading features=========================\n",
      "0     63.80\n",
      "1     33.55\n",
      "2     48.57\n",
      "3     48.03\n",
      "4     55.03\n",
      "5     61.56\n",
      "6     62.21\n",
      "7     58.21\n",
      "8     23.39\n",
      "9   -373.10\n",
      "Name: flesch_reading_ease, dtype: float64\n",
      "0    11.1\n",
      "1    17.1\n",
      "2    13.2\n",
      "3    13.2\n",
      "4    11.7\n",
      "5    11.7\n",
      "6    12.0\n",
      "7    13.3\n",
      "8    18.5\n",
      "9     0.0\n",
      "Name: smog_index, dtype: float64\n",
      "0      8.3\n",
      "1     19.9\n",
      "2     14.2\n",
      "3     12.3\n",
      "4      9.6\n",
      "5      9.2\n",
      "6     11.0\n",
      "7     10.5\n",
      "8     17.6\n",
      "9    180.3\n",
      "Name: flesch_kincaid_grade, dtype: float64\n",
      "[[  63.8    11.1     8.3 ]\n",
      " [  33.55   17.1    19.9 ]\n",
      " [  48.57   13.2    14.2 ]\n",
      " [  48.03   13.2    12.3 ]\n",
      " [  55.03   11.7     9.6 ]\n",
      " [  61.56   11.7     9.2 ]\n",
      " [  62.21   12.     11.  ]\n",
      " [  58.21   13.3    10.5 ]\n",
      " [  23.39   18.5    17.6 ]\n",
      " [-373.1     0.    180.3 ]]\n",
      "\n",
      "0     16.79\n",
      "1     27.29\n",
      "2     22.56\n",
      "3     20.97\n",
      "4     20.26\n",
      "5     16.14\n",
      "6     18.40\n",
      "7     18.97\n",
      "8     26.40\n",
      "9    190.66\n",
      "Name: gunning_fog, dtype: float64\n",
      "0     3.0\n",
      "1     0.0\n",
      "2     0.0\n",
      "3     0.0\n",
      "4     1.0\n",
      "5     6.0\n",
      "6     2.0\n",
      "7     0.0\n",
      "8     0.0\n",
      "9    39.0\n",
      "Name: i_me_myself, dtype: float64\n",
      "0    51.0\n",
      "1    20.0\n",
      "2    28.0\n",
      "3    17.0\n",
      "4    34.0\n",
      "5    32.0\n",
      "6    22.0\n",
      "7    18.0\n",
      "8    35.0\n",
      "9    17.0\n",
      "Name: punct, dtype: float64\n",
      "[[ 3.         51.         56.45614035]\n",
      " [ 0.         20.         32.05882353]\n",
      " [ 0.         28.         29.61818182]\n",
      " [ 0.         17.         23.4       ]\n",
      " [ 1.         34.         31.56363636]\n",
      " [ 6.         32.         36.5       ]\n",
      " [ 2.         22.         31.39285714]\n",
      " [ 0.         18.         26.25      ]\n",
      " [ 0.         35.         38.88679245]\n",
      " [39.         17.         51.        ]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tf_idf_c</th>\n",
       "      <th>Head_Body_Sim</th>\n",
       "      <th>Head_compound</th>\n",
       "      <th>Head_neg</th>\n",
       "      <th>Head_neu</th>\n",
       "      <th>Head_pos</th>\n",
       "      <th>Body_compound</th>\n",
       "      <th>Body_neg</th>\n",
       "      <th>Body_neu</th>\n",
       "      <th>Body_pos</th>\n",
       "      <th>...</th>\n",
       "      <th>smog_index</th>\n",
       "      <th>flesch_kincaid_grade</th>\n",
       "      <th>coleman_liau_index</th>\n",
       "      <th>automated_readability_index</th>\n",
       "      <th>dale_chall_readability_score</th>\n",
       "      <th>difficult_words</th>\n",
       "      <th>linsear_write_formula</th>\n",
       "      <th>gunning_fog</th>\n",
       "      <th>i_me_myself</th>\n",
       "      <th>punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.118339</td>\n",
       "      <td>0.804282</td>\n",
       "      <td>-0.8238</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.116</td>\n",
       "      <td>-0.119276</td>\n",
       "      <td>0.117241</td>\n",
       "      <td>0.806000</td>\n",
       "      <td>0.076724</td>\n",
       "      <td>...</td>\n",
       "      <td>11.1</td>\n",
       "      <td>8.3</td>\n",
       "      <td>13.34</td>\n",
       "      <td>11.6</td>\n",
       "      <td>7.75</td>\n",
       "      <td>107.0</td>\n",
       "      <td>8.285714</td>\n",
       "      <td>16.79</td>\n",
       "      <td>3.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006971</td>\n",
       "      <td>0.971542</td>\n",
       "      <td>-0.4215</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.447000</td>\n",
       "      <td>0.047333</td>\n",
       "      <td>0.826000</td>\n",
       "      <td>0.126667</td>\n",
       "      <td>...</td>\n",
       "      <td>17.1</td>\n",
       "      <td>19.9</td>\n",
       "      <td>12.32</td>\n",
       "      <td>24.7</td>\n",
       "      <td>8.67</td>\n",
       "      <td>48.0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>27.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.073704</td>\n",
       "      <td>0.968892</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.045808</td>\n",
       "      <td>0.044583</td>\n",
       "      <td>0.685500</td>\n",
       "      <td>0.269833</td>\n",
       "      <td>...</td>\n",
       "      <td>13.2</td>\n",
       "      <td>14.2</td>\n",
       "      <td>11.50</td>\n",
       "      <td>16.9</td>\n",
       "      <td>8.41</td>\n",
       "      <td>57.0</td>\n",
       "      <td>16.250000</td>\n",
       "      <td>22.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.260532</td>\n",
       "      <td>0.914280</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.030663</td>\n",
       "      <td>0.097875</td>\n",
       "      <td>0.748500</td>\n",
       "      <td>0.153750</td>\n",
       "      <td>...</td>\n",
       "      <td>13.2</td>\n",
       "      <td>12.3</td>\n",
       "      <td>13.87</td>\n",
       "      <td>15.2</td>\n",
       "      <td>8.62</td>\n",
       "      <td>45.0</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>20.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.294392</td>\n",
       "      <td>0.930432</td>\n",
       "      <td>-0.5994</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.159617</td>\n",
       "      <td>0.121278</td>\n",
       "      <td>0.807167</td>\n",
       "      <td>0.071556</td>\n",
       "      <td>...</td>\n",
       "      <td>11.7</td>\n",
       "      <td>9.6</td>\n",
       "      <td>13.28</td>\n",
       "      <td>11.7</td>\n",
       "      <td>9.09</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8.571429</td>\n",
       "      <td>20.26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tf_idf_c  Head_Body_Sim  Head_compound  Head_neg  Head_neu  Head_pos  \\\n",
       "0  0.118339       0.804282        -0.8238     0.580     0.304     0.116   \n",
       "1  0.006971       0.971542        -0.4215     0.201     0.714     0.084   \n",
       "2  0.073704       0.968892         0.0000     0.000     1.000     0.000   \n",
       "3  0.260532       0.914280         0.0000     0.000     1.000     0.000   \n",
       "4  0.294392       0.930432        -0.5994     0.438     0.562     0.000   \n",
       "\n",
       "   Body_compound  Body_neg  Body_neu  Body_pos  ...    smog_index  \\\n",
       "0      -0.119276  0.117241  0.806000  0.076724  ...          11.1   \n",
       "1       0.447000  0.047333  0.826000  0.126667  ...          17.1   \n",
       "2       0.045808  0.044583  0.685500  0.269833  ...          13.2   \n",
       "3      -0.030663  0.097875  0.748500  0.153750  ...          13.2   \n",
       "4      -0.159617  0.121278  0.807167  0.071556  ...          11.7   \n",
       "\n",
       "   flesch_kincaid_grade  coleman_liau_index  automated_readability_index  \\\n",
       "0                   8.3               13.34                         11.6   \n",
       "1                  19.9               12.32                         24.7   \n",
       "2                  14.2               11.50                         16.9   \n",
       "3                  12.3               13.87                         15.2   \n",
       "4                   9.6               13.28                         11.7   \n",
       "\n",
       "   dale_chall_readability_score  difficult_words  linsear_write_formula  \\\n",
       "0                          7.75            107.0               8.285714   \n",
       "1                          8.67             48.0              21.000000   \n",
       "2                          8.41             57.0              16.250000   \n",
       "3                          8.62             45.0              15.750000   \n",
       "4                          9.09             81.0               8.571429   \n",
       "\n",
       "   gunning_fog  i_me_myself  punct  \n",
       "0        16.79          3.0   51.0  \n",
       "1        27.29          0.0   20.0  \n",
       "2        22.56          0.0   28.0  \n",
       "3        20.97          0.0   17.0  \n",
       "4        20.26          1.0   34.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempd= get_features(X_s)\n",
    "print(tempd.keys())\n",
    "print('======'*5+'Tf_idf similarity'+'====='*5)\n",
    "print(tempd['tf_idf_c'][:10], tf_idf_c[:10],sep = '\\n')\n",
    "\n",
    "print('======'*5+'Head Body similarity'+'====='*5)\n",
    "print(tempd['Head_Body_Sim'][:10], head_body_sim[:10],sep = '\\n')\n",
    "\n",
    "print('======'*5+'Sentiments'+'====='*5)\n",
    "print(tempd['Head_compound'][:10], tempd['Head_neg'][:10], \\\n",
    "tempd['Head_neu'][:10], tempd['Head_pos'][:10], head_senti[:10],sep = '\\n')\n",
    "\n",
    "print('======'*5+'Article body'+'====='*5)\n",
    "\n",
    "print(tempd['Body_compound'][:10], tempd['Body_neg'][:10], \\\n",
    "tempd['Body_neu'][:10], tempd['Body_pos'][:10], body_senti[:10],sep = '\\n')\n",
    "\n",
    "print('======'*5+'Reading features'+'====='*5)\n",
    "\n",
    "print(tempd['flesch_reading_ease'][:10], tempd['smog_index'][:10], tempd['flesch_kincaid_grade'][:10] \\\n",
    ", read_f[:,:3][:10],sep = '\\n')\n",
    "\n",
    "print()\n",
    "\n",
    "print(tempd['gunning_fog'][:10], tempd['i_me_myself'][:10], tempd['punct'][:10] \\\n",
    ", read_f[:,-3:][:10],sep = '\\n')\n",
    "\n",
    "t = pd.DataFrame(tempd)\n",
    "t.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DUMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "opensources_path = ['datasets/generated_feature.pkl', 'datasets/generated_feature_targets.pkl']\n",
    "\n",
    "kaggle_path = ['datasets/generated_feature_kaggle.pkl', 'datasets/targets_kaggle.pkl']\n",
    "\n",
    "d3_path = ['datasets/generated_feature_new.pkl', 'datasets/targets_new.pkl']\n",
    "tdic = {0:'REAL', 1:'FAKE'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opensources...\n",
      "Nan Before False\n",
      "Nan After False\n",
      "OpensourcesShape: (11161, 163)\n",
      "Class\tCounts\n",
      "0    5776\n",
      "1    5385\n",
      "Name: target, dtype: int64\n",
      "Tf_idf shape: (11161,)\n",
      "Headline sentiments shape:(11161, 4)\n",
      " Body sentiments shape: (11161, 4)\n",
      "\n",
      "Readibility features shape: (11161, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tf_idf_c</th>\n",
       "      <th>Head_Body_Sim</th>\n",
       "      <th>Head_compound</th>\n",
       "      <th>Head_neg</th>\n",
       "      <th>Head_neu</th>\n",
       "      <th>Head_pos</th>\n",
       "      <th>Body_compound</th>\n",
       "      <th>Body_neg</th>\n",
       "      <th>Body_neu</th>\n",
       "      <th>Body_pos</th>\n",
       "      <th>...</th>\n",
       "      <th>coleman_liau_index</th>\n",
       "      <th>automated_readability_index</th>\n",
       "      <th>dale_chall_readability_score</th>\n",
       "      <th>difficult_words</th>\n",
       "      <th>linsear_write_formula</th>\n",
       "      <th>gunning_fog</th>\n",
       "      <th>i_me_myself</th>\n",
       "      <th>punct</th>\n",
       "      <th>target</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.118339</td>\n",
       "      <td>0.804282</td>\n",
       "      <td>-0.8238</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.116</td>\n",
       "      <td>-0.119276</td>\n",
       "      <td>0.117241</td>\n",
       "      <td>0.806000</td>\n",
       "      <td>0.076724</td>\n",
       "      <td>...</td>\n",
       "      <td>13.34</td>\n",
       "      <td>11.6</td>\n",
       "      <td>7.75</td>\n",
       "      <td>107.0</td>\n",
       "      <td>8.285714</td>\n",
       "      <td>16.79</td>\n",
       "      <td>3.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>REAL</td>\n",
       "      <td>Dataset - 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006971</td>\n",
       "      <td>0.971542</td>\n",
       "      <td>-0.4215</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.447000</td>\n",
       "      <td>0.047333</td>\n",
       "      <td>0.826000</td>\n",
       "      <td>0.126667</td>\n",
       "      <td>...</td>\n",
       "      <td>12.32</td>\n",
       "      <td>24.7</td>\n",
       "      <td>8.67</td>\n",
       "      <td>48.0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>27.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>Dataset - 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.073704</td>\n",
       "      <td>0.968892</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.045808</td>\n",
       "      <td>0.044583</td>\n",
       "      <td>0.685500</td>\n",
       "      <td>0.269833</td>\n",
       "      <td>...</td>\n",
       "      <td>11.50</td>\n",
       "      <td>16.9</td>\n",
       "      <td>8.41</td>\n",
       "      <td>57.0</td>\n",
       "      <td>16.250000</td>\n",
       "      <td>22.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>Dataset - 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.260532</td>\n",
       "      <td>0.914280</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.030663</td>\n",
       "      <td>0.097875</td>\n",
       "      <td>0.748500</td>\n",
       "      <td>0.153750</td>\n",
       "      <td>...</td>\n",
       "      <td>13.87</td>\n",
       "      <td>15.2</td>\n",
       "      <td>8.62</td>\n",
       "      <td>45.0</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>20.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>Dataset - 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.294392</td>\n",
       "      <td>0.930432</td>\n",
       "      <td>-0.5994</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.159617</td>\n",
       "      <td>0.121278</td>\n",
       "      <td>0.807167</td>\n",
       "      <td>0.071556</td>\n",
       "      <td>...</td>\n",
       "      <td>13.28</td>\n",
       "      <td>11.7</td>\n",
       "      <td>9.09</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8.571429</td>\n",
       "      <td>20.26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>Dataset - 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tf_idf_c  Head_Body_Sim  Head_compound  Head_neg  Head_neu  Head_pos  \\\n",
       "0  0.118339       0.804282        -0.8238     0.580     0.304     0.116   \n",
       "1  0.006971       0.971542        -0.4215     0.201     0.714     0.084   \n",
       "2  0.073704       0.968892         0.0000     0.000     1.000     0.000   \n",
       "3  0.260532       0.914280         0.0000     0.000     1.000     0.000   \n",
       "4  0.294392       0.930432        -0.5994     0.438     0.562     0.000   \n",
       "\n",
       "   Body_compound  Body_neg  Body_neu  Body_pos     ...       \\\n",
       "0      -0.119276  0.117241  0.806000  0.076724     ...        \n",
       "1       0.447000  0.047333  0.826000  0.126667     ...        \n",
       "2       0.045808  0.044583  0.685500  0.269833     ...        \n",
       "3      -0.030663  0.097875  0.748500  0.153750     ...        \n",
       "4      -0.159617  0.121278  0.807167  0.071556     ...        \n",
       "\n",
       "   coleman_liau_index  automated_readability_index  \\\n",
       "0               13.34                         11.6   \n",
       "1               12.32                         24.7   \n",
       "2               11.50                         16.9   \n",
       "3               13.87                         15.2   \n",
       "4               13.28                         11.7   \n",
       "\n",
       "   dale_chall_readability_score  difficult_words  linsear_write_formula  \\\n",
       "0                          7.75            107.0               8.285714   \n",
       "1                          8.67             48.0              21.000000   \n",
       "2                          8.41             57.0              16.250000   \n",
       "3                          8.62             45.0              15.750000   \n",
       "4                          9.09             81.0               8.571429   \n",
       "\n",
       "   gunning_fog  i_me_myself  punct  target      dataset  \n",
       "0        16.79          3.0   51.0    REAL  Dataset - 1  \n",
       "1        27.29          0.0   20.0    FAKE  Dataset - 1  \n",
       "2        22.56          0.0   28.0    FAKE  Dataset - 1  \n",
       "3        20.97          0.0   17.0    FAKE  Dataset - 1  \n",
       "4        20.26          1.0   34.0    FAKE  Dataset - 1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Opensource dataset dump\n",
    "open_f, open_t = get_shit(opensources_path[0], opensources_path[1], 'Opensources')\n",
    "print('Class\\tCounts',open_t.value_counts(), sep = '\\n')\n",
    "# Making dataframes\n",
    "open_df = get_features(open_f)\n",
    "\n",
    "open_df['target'] = open_t\n",
    "\n",
    "open_df['dataset'] = 'Dataset - 1'\n",
    "open_df['target'] = open_df['target'].apply(lambda x: tdic[x])\n",
    "open_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle...\n",
      "Nan Before True\n",
      "Nan After False\n",
      "KaggleShape: (20800, 163)\n",
      "Class\tCounts\n",
      "1    10413\n",
      "0    10387\n",
      "Name: target, dtype: int64\n",
      "Tf_idf shape: (20800,)\n",
      "Headline sentiments shape:(20800, 4)\n",
      " Body sentiments shape: (20800, 4)\n",
      "\n",
      "Readibility features shape: (20800, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tf_idf_c</th>\n",
       "      <th>Head_Body_Sim</th>\n",
       "      <th>Head_compound</th>\n",
       "      <th>Head_neg</th>\n",
       "      <th>Head_neu</th>\n",
       "      <th>Head_pos</th>\n",
       "      <th>Body_compound</th>\n",
       "      <th>Body_neg</th>\n",
       "      <th>Body_neu</th>\n",
       "      <th>Body_pos</th>\n",
       "      <th>...</th>\n",
       "      <th>coleman_liau_index</th>\n",
       "      <th>automated_readability_index</th>\n",
       "      <th>dale_chall_readability_score</th>\n",
       "      <th>difficult_words</th>\n",
       "      <th>linsear_write_formula</th>\n",
       "      <th>gunning_fog</th>\n",
       "      <th>i_me_myself</th>\n",
       "      <th>punct</th>\n",
       "      <th>target</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.356702</td>\n",
       "      <td>0.848848</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.002041</td>\n",
       "      <td>0.037054</td>\n",
       "      <td>0.920405</td>\n",
       "      <td>0.042568</td>\n",
       "      <td>...</td>\n",
       "      <td>12.25</td>\n",
       "      <td>15.9</td>\n",
       "      <td>7.77</td>\n",
       "      <td>144.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>19.94</td>\n",
       "      <td>2.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>Dataset - 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.114182</td>\n",
       "      <td>0.858105</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.019269</td>\n",
       "      <td>0.083345</td>\n",
       "      <td>0.834759</td>\n",
       "      <td>0.081862</td>\n",
       "      <td>...</td>\n",
       "      <td>11.38</td>\n",
       "      <td>19.1</td>\n",
       "      <td>8.29</td>\n",
       "      <td>130.0</td>\n",
       "      <td>15.250000</td>\n",
       "      <td>23.52</td>\n",
       "      <td>7.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>REAL</td>\n",
       "      <td>Dataset - 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.072524</td>\n",
       "      <td>0.921988</td>\n",
       "      <td>-0.3182</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.076524</td>\n",
       "      <td>0.083588</td>\n",
       "      <td>0.805510</td>\n",
       "      <td>0.110980</td>\n",
       "      <td>...</td>\n",
       "      <td>12.83</td>\n",
       "      <td>22.3</td>\n",
       "      <td>8.43</td>\n",
       "      <td>227.0</td>\n",
       "      <td>10.833333</td>\n",
       "      <td>24.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>Dataset - 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.361706</td>\n",
       "      <td>0.947477</td>\n",
       "      <td>-0.6705</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.461196</td>\n",
       "      <td>0.191074</td>\n",
       "      <td>0.792741</td>\n",
       "      <td>0.016185</td>\n",
       "      <td>...</td>\n",
       "      <td>11.51</td>\n",
       "      <td>22.7</td>\n",
       "      <td>8.17</td>\n",
       "      <td>85.0</td>\n",
       "      <td>18.666667</td>\n",
       "      <td>25.22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>Dataset - 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.268379</td>\n",
       "      <td>0.943439</td>\n",
       "      <td>-0.7964</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.397360</td>\n",
       "      <td>0.122800</td>\n",
       "      <td>0.851800</td>\n",
       "      <td>0.025400</td>\n",
       "      <td>...</td>\n",
       "      <td>13.66</td>\n",
       "      <td>79.2</td>\n",
       "      <td>14.53</td>\n",
       "      <td>32.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>71.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>Dataset - 2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tf_idf_c  Head_Body_Sim  Head_compound  Head_neg  Head_neu  Head_pos  \\\n",
       "0  0.356702       0.848848         0.0000     0.000     1.000     0.000   \n",
       "1  0.114182       0.858105         0.0000     0.000     1.000     0.000   \n",
       "2  0.072524       0.921988        -0.3182     0.330     0.459     0.211   \n",
       "3  0.361706       0.947477        -0.6705     0.333     0.667     0.000   \n",
       "4  0.268379       0.943439        -0.7964     0.372     0.628     0.000   \n",
       "\n",
       "   Body_compound  Body_neg  Body_neu  Body_pos     ...       \\\n",
       "0      -0.002041  0.037054  0.920405  0.042568     ...        \n",
       "1       0.019269  0.083345  0.834759  0.081862     ...        \n",
       "2       0.076524  0.083588  0.805510  0.110980     ...        \n",
       "3      -0.461196  0.191074  0.792741  0.016185     ...        \n",
       "4      -0.397360  0.122800  0.851800  0.025400     ...        \n",
       "\n",
       "   coleman_liau_index  automated_readability_index  \\\n",
       "0               12.25                         15.9   \n",
       "1               11.38                         19.1   \n",
       "2               12.83                         22.3   \n",
       "3               11.51                         22.7   \n",
       "4               13.66                         79.2   \n",
       "\n",
       "   dale_chall_readability_score  difficult_words  linsear_write_formula  \\\n",
       "0                          7.77            144.0              20.000000   \n",
       "1                          8.29            130.0              15.250000   \n",
       "2                          8.43            227.0              10.833333   \n",
       "3                          8.17             85.0              18.666667   \n",
       "4                         14.53             32.0              30.000000   \n",
       "\n",
       "   gunning_fog  i_me_myself  punct  target      dataset  \n",
       "0        19.94          2.0   66.0    FAKE  Dataset - 2  \n",
       "1        23.52          7.0   66.0    REAL  Dataset - 2  \n",
       "2        24.99          1.0  130.0    FAKE  Dataset - 2  \n",
       "3        25.22          1.0   36.0    FAKE  Dataset - 2  \n",
       "4        71.57          0.0   15.0    FAKE  Dataset - 2  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kaggle dataset dump.\n",
    " \n",
    "kaggle_f, kaggle_t = get_shit(kaggle_path[0], kaggle_path[1], 'Kaggle')\n",
    "print('Class\\tCounts', kaggle_t.value_counts(), sep = '\\n')\n",
    "\n",
    "kaggle_df = get_features(kaggle_f)\n",
    "kaggle_df['target'] = kaggle_t.map(lambda x:tdic[x])\n",
    "kaggle_df['dataset'] = 'Dataset - 2'\n",
    "kaggle_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D -- 3...\n",
      "Nan Before True\n",
      "Nan After False\n",
      "D -- 3Shape: (6335, 163)\n",
      "Class\tCounts\n",
      "0    3171\n",
      "1    3164\n",
      "Name: target, dtype: int64\n",
      "Tf_idf shape: (6335,)\n",
      "Headline sentiments shape:(6335, 4)\n",
      " Body sentiments shape: (6335, 4)\n",
      "\n",
      "Readibility features shape: (6335, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tf_idf_c</th>\n",
       "      <th>Head_Body_Sim</th>\n",
       "      <th>Head_compound</th>\n",
       "      <th>Head_neg</th>\n",
       "      <th>Head_neu</th>\n",
       "      <th>Head_pos</th>\n",
       "      <th>Body_compound</th>\n",
       "      <th>Body_neg</th>\n",
       "      <th>Body_neu</th>\n",
       "      <th>Body_pos</th>\n",
       "      <th>...</th>\n",
       "      <th>coleman_liau_index</th>\n",
       "      <th>automated_readability_index</th>\n",
       "      <th>dale_chall_readability_score</th>\n",
       "      <th>difficult_words</th>\n",
       "      <th>linsear_write_formula</th>\n",
       "      <th>gunning_fog</th>\n",
       "      <th>i_me_myself</th>\n",
       "      <th>punct</th>\n",
       "      <th>target</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.109181</td>\n",
       "      <td>0.822768</td>\n",
       "      <td>-0.4939</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.210469</td>\n",
       "      <td>0.162989</td>\n",
       "      <td>0.779333</td>\n",
       "      <td>0.057678</td>\n",
       "      <td>...</td>\n",
       "      <td>10.86</td>\n",
       "      <td>12.7</td>\n",
       "      <td>7.38</td>\n",
       "      <td>213.0</td>\n",
       "      <td>8.833333</td>\n",
       "      <td>17.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>Dataset - 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.150184</td>\n",
       "      <td>0.940949</td>\n",
       "      <td>-0.5267</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.036058</td>\n",
       "      <td>0.063000</td>\n",
       "      <td>0.836500</td>\n",
       "      <td>0.062038</td>\n",
       "      <td>...</td>\n",
       "      <td>11.78</td>\n",
       "      <td>13.6</td>\n",
       "      <td>7.89</td>\n",
       "      <td>87.0</td>\n",
       "      <td>8.571429</td>\n",
       "      <td>19.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>Dataset - 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.129203</td>\n",
       "      <td>0.958502</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.031881</td>\n",
       "      <td>0.047563</td>\n",
       "      <td>0.883937</td>\n",
       "      <td>0.068500</td>\n",
       "      <td>...</td>\n",
       "      <td>12.14</td>\n",
       "      <td>23.3</td>\n",
       "      <td>8.71</td>\n",
       "      <td>80.0</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>26.66</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>REAL</td>\n",
       "      <td>Dataset - 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.049776</td>\n",
       "      <td>0.920681</td>\n",
       "      <td>-0.3595</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.143</td>\n",
       "      <td>-0.095876</td>\n",
       "      <td>0.084765</td>\n",
       "      <td>0.867471</td>\n",
       "      <td>0.047706</td>\n",
       "      <td>...</td>\n",
       "      <td>15.73</td>\n",
       "      <td>23.3</td>\n",
       "      <td>9.25</td>\n",
       "      <td>97.0</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>26.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>Dataset - 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.081292</td>\n",
       "      <td>0.949463</td>\n",
       "      <td>-0.3612</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.220305</td>\n",
       "      <td>0.055952</td>\n",
       "      <td>0.795905</td>\n",
       "      <td>0.148190</td>\n",
       "      <td>...</td>\n",
       "      <td>11.38</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.67</td>\n",
       "      <td>46.0</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>21.88</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>REAL</td>\n",
       "      <td>Dataset - 3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tf_idf_c  Head_Body_Sim  Head_compound  Head_neg  Head_neu  Head_pos  \\\n",
       "0  0.109181       0.822768        -0.4939     0.444     0.556     0.000   \n",
       "1  0.150184       0.940949        -0.5267     0.256     0.625     0.119   \n",
       "2  0.129203       0.958502         0.3612     0.000     0.762     0.238   \n",
       "3  0.049776       0.920681        -0.3595     0.266     0.591     0.143   \n",
       "4  0.081292       0.949463        -0.3612     0.243     0.654     0.103   \n",
       "\n",
       "   Body_compound  Body_neg  Body_neu  Body_pos     ...       \\\n",
       "0      -0.210469  0.162989  0.779333  0.057678     ...        \n",
       "1       0.036058  0.063000  0.836500  0.062038     ...        \n",
       "2       0.031881  0.047563  0.883937  0.068500     ...        \n",
       "3      -0.095876  0.084765  0.867471  0.047706     ...        \n",
       "4       0.220305  0.055952  0.795905  0.148190     ...        \n",
       "\n",
       "   coleman_liau_index  automated_readability_index  \\\n",
       "0               10.86                         12.7   \n",
       "1               11.78                         13.6   \n",
       "2               12.14                         23.3   \n",
       "3               15.73                         23.3   \n",
       "4               11.38                         19.0   \n",
       "\n",
       "   dale_chall_readability_score  difficult_words  linsear_write_formula  \\\n",
       "0                          7.38            213.0               8.833333   \n",
       "1                          7.89             87.0               8.571429   \n",
       "2                          8.71             80.0              10.333333   \n",
       "3                          9.25             97.0              33.000000   \n",
       "4                          7.67             46.0              10.333333   \n",
       "\n",
       "   gunning_fog  i_me_myself  punct  target      dataset  \n",
       "0        17.81          0.0  104.0    FAKE  Dataset - 3  \n",
       "1        19.20          0.0   43.0    FAKE  Dataset - 3  \n",
       "2        26.66          2.0   35.0    REAL  Dataset - 3  \n",
       "3        26.28          0.0   43.0    FAKE  Dataset - 3  \n",
       "4        21.88          1.0   38.0    REAL  Dataset - 3  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset 3\n",
    "d3_f, d3_t = get_shit(d3_path[0], d3_path[1], 'D -- 3')\n",
    "print('Class\\tCounts', d3_t.value_counts(), sep = '\\n')\n",
    "\n",
    "d3_df = get_features(d3_f)\n",
    "d3_df['target'] = d3_t.map(lambda x:tdic[x])\n",
    "d3_df['dataset'] = 'Dataset - 3'\n",
    "d3_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tf_idf_c</th>\n",
       "      <th>Head_Body_Sim</th>\n",
       "      <th>Head_compound</th>\n",
       "      <th>Head_neg</th>\n",
       "      <th>Head_neu</th>\n",
       "      <th>Head_pos</th>\n",
       "      <th>Body_compound</th>\n",
       "      <th>Body_neg</th>\n",
       "      <th>Body_neu</th>\n",
       "      <th>Body_pos</th>\n",
       "      <th>...</th>\n",
       "      <th>coleman_liau_index</th>\n",
       "      <th>automated_readability_index</th>\n",
       "      <th>dale_chall_readability_score</th>\n",
       "      <th>difficult_words</th>\n",
       "      <th>linsear_write_formula</th>\n",
       "      <th>gunning_fog</th>\n",
       "      <th>i_me_myself</th>\n",
       "      <th>punct</th>\n",
       "      <th>target</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.118339</td>\n",
       "      <td>0.804282</td>\n",
       "      <td>-0.8238</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.116</td>\n",
       "      <td>-0.119276</td>\n",
       "      <td>0.117241</td>\n",
       "      <td>0.806000</td>\n",
       "      <td>0.076724</td>\n",
       "      <td>...</td>\n",
       "      <td>13.34</td>\n",
       "      <td>11.6</td>\n",
       "      <td>7.75</td>\n",
       "      <td>107.0</td>\n",
       "      <td>8.285714</td>\n",
       "      <td>16.79</td>\n",
       "      <td>3.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>REAL</td>\n",
       "      <td>Dataset - 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006971</td>\n",
       "      <td>0.971542</td>\n",
       "      <td>-0.4215</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.447000</td>\n",
       "      <td>0.047333</td>\n",
       "      <td>0.826000</td>\n",
       "      <td>0.126667</td>\n",
       "      <td>...</td>\n",
       "      <td>12.32</td>\n",
       "      <td>24.7</td>\n",
       "      <td>8.67</td>\n",
       "      <td>48.0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>27.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>Dataset - 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.073704</td>\n",
       "      <td>0.968892</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.045808</td>\n",
       "      <td>0.044583</td>\n",
       "      <td>0.685500</td>\n",
       "      <td>0.269833</td>\n",
       "      <td>...</td>\n",
       "      <td>11.50</td>\n",
       "      <td>16.9</td>\n",
       "      <td>8.41</td>\n",
       "      <td>57.0</td>\n",
       "      <td>16.250000</td>\n",
       "      <td>22.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>Dataset - 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.260532</td>\n",
       "      <td>0.914280</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.030663</td>\n",
       "      <td>0.097875</td>\n",
       "      <td>0.748500</td>\n",
       "      <td>0.153750</td>\n",
       "      <td>...</td>\n",
       "      <td>13.87</td>\n",
       "      <td>15.2</td>\n",
       "      <td>8.62</td>\n",
       "      <td>45.0</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>20.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>Dataset - 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.294392</td>\n",
       "      <td>0.930432</td>\n",
       "      <td>-0.5994</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.159617</td>\n",
       "      <td>0.121278</td>\n",
       "      <td>0.807167</td>\n",
       "      <td>0.071556</td>\n",
       "      <td>...</td>\n",
       "      <td>13.28</td>\n",
       "      <td>11.7</td>\n",
       "      <td>9.09</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8.571429</td>\n",
       "      <td>20.26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>Dataset - 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tf_idf_c  Head_Body_Sim  Head_compound  Head_neg  Head_neu  Head_pos  \\\n",
       "0  0.118339       0.804282        -0.8238     0.580     0.304     0.116   \n",
       "1  0.006971       0.971542        -0.4215     0.201     0.714     0.084   \n",
       "2  0.073704       0.968892         0.0000     0.000     1.000     0.000   \n",
       "3  0.260532       0.914280         0.0000     0.000     1.000     0.000   \n",
       "4  0.294392       0.930432        -0.5994     0.438     0.562     0.000   \n",
       "\n",
       "   Body_compound  Body_neg  Body_neu  Body_pos     ...       \\\n",
       "0      -0.119276  0.117241  0.806000  0.076724     ...        \n",
       "1       0.447000  0.047333  0.826000  0.126667     ...        \n",
       "2       0.045808  0.044583  0.685500  0.269833     ...        \n",
       "3      -0.030663  0.097875  0.748500  0.153750     ...        \n",
       "4      -0.159617  0.121278  0.807167  0.071556     ...        \n",
       "\n",
       "   coleman_liau_index  automated_readability_index  \\\n",
       "0               13.34                         11.6   \n",
       "1               12.32                         24.7   \n",
       "2               11.50                         16.9   \n",
       "3               13.87                         15.2   \n",
       "4               13.28                         11.7   \n",
       "\n",
       "   dale_chall_readability_score  difficult_words  linsear_write_formula  \\\n",
       "0                          7.75            107.0               8.285714   \n",
       "1                          8.67             48.0              21.000000   \n",
       "2                          8.41             57.0              16.250000   \n",
       "3                          8.62             45.0              15.750000   \n",
       "4                          9.09             81.0               8.571429   \n",
       "\n",
       "   gunning_fog  i_me_myself  punct  target      dataset  \n",
       "0        16.79          3.0   51.0    REAL  Dataset - 1  \n",
       "1        27.29          0.0   20.0    FAKE  Dataset - 1  \n",
       "2        22.56          0.0   28.0    FAKE  Dataset - 1  \n",
       "3        20.97          0.0   17.0    FAKE  Dataset - 1  \n",
       "4        20.26          1.0   34.0    FAKE  Dataset - 1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combining Dataframe\n",
    "f_combined = pd.concat([open_df, kaggle_df, d3_df], ignore_index = True)\n",
    "f_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38296 entries, 0 to 38295\n",
      "Data columns (total 23 columns):\n",
      "tf_idf_c                        38296 non-null float64\n",
      "Head_Body_Sim                   38296 non-null float64\n",
      "Head_compound                   38296 non-null float64\n",
      "Head_neg                        38296 non-null float64\n",
      "Head_neu                        38296 non-null float64\n",
      "Head_pos                        38296 non-null float64\n",
      "Body_compound                   38296 non-null float64\n",
      "Body_neg                        38296 non-null float64\n",
      "Body_neu                        38296 non-null float64\n",
      "Body_pos                        38296 non-null float64\n",
      "flesch_reading_ease             38296 non-null float64\n",
      "smog_index                      38296 non-null float64\n",
      "flesch_kincaid_grade            38296 non-null float64\n",
      "coleman_liau_index              38296 non-null float64\n",
      "automated_readability_index     38296 non-null float64\n",
      "dale_chall_readability_score    38296 non-null float64\n",
      "difficult_words                 38296 non-null float64\n",
      "linsear_write_formula           38296 non-null float64\n",
      "gunning_fog                     38296 non-null float64\n",
      "i_me_myself                     38296 non-null float64\n",
      "punct                           38296 non-null float64\n",
      "target                          38296 non-null object\n",
      "dataset                         38296 non-null object\n",
      "dtypes: float64(21), object(2)\n",
      "memory usage: 6.7+ MB\n"
     ]
    }
   ],
   "source": [
    "f_combined.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count and other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_columns = ['count_of_Headline_unigram', 'count_of_unique_Headline_unigram', \n",
    "              'ratio_of_unique_Headline_unigram', 'count_of_Headline_bigram', \n",
    "              'count_of_unique_Headline_bigram', 'ratio_of_unique_Headline_bigram', \n",
    "              'count_of_Headline_trigram', 'count_of_unique_Headline_trigram', \n",
    "              'ratio_of_unique_Headline_trigram', 'count_of_articleBody_unigram', \n",
    "              'count_of_unique_articleBody_unigram', 'ratio_of_unique_articleBody_unigram', \n",
    "              'count_of_articleBody_bigram', 'count_of_unique_articleBody_bigram', \n",
    "              'ratio_of_unique_articleBody_bigram', 'count_of_articleBody_trigram', \n",
    "              'count_of_unique_articleBody_trigram', 'ratio_of_unique_articleBody_trigram', \n",
    "              'count_of_Headline_unigram_in_articleBody', \n",
    "              'ratio_of_Headline_unigram_in_articleBody', \n",
    "              'count_of_Headline_bigram_in_articleBody', \n",
    "              'ratio_of_Headline_bigram_in_articleBody', 'count_of_Headline_trigram_in_articleBody', \n",
    "              'ratio_of_Headline_trigram_in_articleBody', 'len_sent_Headline', \n",
    "              'len_sent_articleBody', 'fake_exist', 'fraud_exist', 'hoax_exist', \n",
    "              'false_exist', 'deny_exist', 'denies_exist', 'not_exist', 'despite_exist', \n",
    "              'nope_exist', 'doubt_exist', 'doubts_exist', 'bogus_exist', 'debunk_exist', \n",
    "              'pranks_exist', 'retract_exist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count features shape (11161, 41)\n",
      "Word_vec shape\n",
      "Head:\t(11161, 50) Body:\t(11161, 50)\n",
      "Count features shape (20800, 41)\n",
      "Word_vec shape\n",
      "Head:\t(20800, 50) Body:\t(20800, 50)\n",
      "Count features shape (6335, 41)\n",
      "Word_vec shape\n",
      "Head:\t(6335, 50) Body:\t(6335, 50)\n"
     ]
    }
   ],
   "source": [
    "# Opensources\n",
    "Open_cf, Open_wv_head, Open_wv_body = get_count_wordvec(open_f)\n",
    "# Kaggle\n",
    "kaggle_cf, kaggle_wv_head, kaggle_wv_body = get_count_wordvec(kaggle_f)\n",
    "# D3\n",
    "d3_cf, d3_wv_head, d3_wv_body = get_count_wordvec(d3_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7., 7., 1., ..., 0., 0., 0.],\n",
       "       [9., 9., 1., ..., 0., 0., 0.],\n",
       "       [2., 2., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [8., 8., 1., ..., 0., 0., 0.],\n",
       "       [6., 6., 1., ..., 0., 0., 0.],\n",
       "       [9., 9., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Open_cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframes\n",
    "op_df = pd.DataFrame(Open_cf,columns=cf_columns)\n",
    "\n",
    "k_df = pd.DataFrame(kaggle_cf,columns=cf_columns)\n",
    "\n",
    "cf_df = pd.DataFrame(d3_cf,columns=cf_columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11161\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_of_Headline_unigram</th>\n",
       "      <th>count_of_unique_Headline_unigram</th>\n",
       "      <th>ratio_of_unique_Headline_unigram</th>\n",
       "      <th>count_of_Headline_bigram</th>\n",
       "      <th>count_of_unique_Headline_bigram</th>\n",
       "      <th>ratio_of_unique_Headline_bigram</th>\n",
       "      <th>count_of_Headline_trigram</th>\n",
       "      <th>count_of_unique_Headline_trigram</th>\n",
       "      <th>ratio_of_unique_Headline_trigram</th>\n",
       "      <th>count_of_articleBody_unigram</th>\n",
       "      <th>...</th>\n",
       "      <th>denies_exist</th>\n",
       "      <th>not_exist</th>\n",
       "      <th>despite_exist</th>\n",
       "      <th>nope_exist</th>\n",
       "      <th>doubt_exist</th>\n",
       "      <th>doubts_exist</th>\n",
       "      <th>bogus_exist</th>\n",
       "      <th>debunk_exist</th>\n",
       "      <th>pranks_exist</th>\n",
       "      <th>retract_exist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   count_of_Headline_unigram  count_of_unique_Headline_unigram  \\\n",
       "0                        7.0                               7.0   \n",
       "1                        9.0                               9.0   \n",
       "2                        2.0                               2.0   \n",
       "3                        7.0                               7.0   \n",
       "4                        4.0                               4.0   \n",
       "\n",
       "   ratio_of_unique_Headline_unigram  count_of_Headline_bigram  \\\n",
       "0                               1.0                       6.0   \n",
       "1                               1.0                       8.0   \n",
       "2                               1.0                       1.0   \n",
       "3                               1.0                       6.0   \n",
       "4                               1.0                       3.0   \n",
       "\n",
       "   count_of_unique_Headline_bigram  ratio_of_unique_Headline_bigram  \\\n",
       "0                              6.0                              1.0   \n",
       "1                              8.0                              1.0   \n",
       "2                              1.0                              1.0   \n",
       "3                              6.0                              1.0   \n",
       "4                              3.0                              1.0   \n",
       "\n",
       "   count_of_Headline_trigram  count_of_unique_Headline_trigram  \\\n",
       "0                        5.0                               5.0   \n",
       "1                        7.0                               7.0   \n",
       "2                        1.0                               1.0   \n",
       "3                        5.0                               5.0   \n",
       "4                        2.0                               2.0   \n",
       "\n",
       "   ratio_of_unique_Headline_trigram  count_of_articleBody_unigram  \\\n",
       "0                               1.0                         312.0   \n",
       "1                               1.0                         158.0   \n",
       "2                               1.0                         159.0   \n",
       "3                               1.0                         119.0   \n",
       "4                               1.0                         173.0   \n",
       "\n",
       "       ...        denies_exist  not_exist  despite_exist  nope_exist  \\\n",
       "0      ...                 0.0        0.0            0.0         0.0   \n",
       "1      ...                 0.0        0.0            0.0         0.0   \n",
       "2      ...                 0.0        0.0            0.0         0.0   \n",
       "3      ...                 0.0        0.0            0.0         0.0   \n",
       "4      ...                 0.0        0.0            0.0         0.0   \n",
       "\n",
       "   doubt_exist  doubts_exist  bogus_exist  debunk_exist  pranks_exist  \\\n",
       "0          0.0           0.0          0.0           0.0           0.0   \n",
       "1          0.0           0.0          0.0           0.0           0.0   \n",
       "2          0.0           0.0          0.0           0.0           0.0   \n",
       "3          0.0           0.0          0.0           0.0           0.0   \n",
       "4          0.0           0.0          0.0           0.0           0.0   \n",
       "\n",
       "   retract_exist  \n",
       "0            0.0  \n",
       "1            0.0  \n",
       "2            0.0  \n",
       "3            0.0  \n",
       "4            0.0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(op_df))\n",
    "op_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20800\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_of_Headline_unigram</th>\n",
       "      <th>count_of_unique_Headline_unigram</th>\n",
       "      <th>ratio_of_unique_Headline_unigram</th>\n",
       "      <th>count_of_Headline_bigram</th>\n",
       "      <th>count_of_unique_Headline_bigram</th>\n",
       "      <th>ratio_of_unique_Headline_bigram</th>\n",
       "      <th>count_of_Headline_trigram</th>\n",
       "      <th>count_of_unique_Headline_trigram</th>\n",
       "      <th>ratio_of_unique_Headline_trigram</th>\n",
       "      <th>count_of_articleBody_unigram</th>\n",
       "      <th>...</th>\n",
       "      <th>denies_exist</th>\n",
       "      <th>not_exist</th>\n",
       "      <th>despite_exist</th>\n",
       "      <th>nope_exist</th>\n",
       "      <th>doubt_exist</th>\n",
       "      <th>doubts_exist</th>\n",
       "      <th>bogus_exist</th>\n",
       "      <th>debunk_exist</th>\n",
       "      <th>pranks_exist</th>\n",
       "      <th>retract_exist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>446.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>703.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   count_of_Headline_unigram  count_of_unique_Headline_unigram  \\\n",
       "0                       10.0                              10.0   \n",
       "1                        7.0                               7.0   \n",
       "2                        5.0                               5.0   \n",
       "3                        7.0                               7.0   \n",
       "4                       10.0                               9.0   \n",
       "\n",
       "   ratio_of_unique_Headline_unigram  count_of_Headline_bigram  \\\n",
       "0                               1.0                       9.0   \n",
       "1                               1.0                       6.0   \n",
       "2                               1.0                       4.0   \n",
       "3                               1.0                       6.0   \n",
       "4                               0.9                       9.0   \n",
       "\n",
       "   count_of_unique_Headline_bigram  ratio_of_unique_Headline_bigram  \\\n",
       "0                              9.0                              1.0   \n",
       "1                              6.0                              1.0   \n",
       "2                              4.0                              1.0   \n",
       "3                              6.0                              1.0   \n",
       "4                              9.0                              1.0   \n",
       "\n",
       "   count_of_Headline_trigram  count_of_unique_Headline_trigram  \\\n",
       "0                        8.0                               8.0   \n",
       "1                        5.0                               5.0   \n",
       "2                        3.0                               3.0   \n",
       "3                        5.0                               5.0   \n",
       "4                        8.0                               8.0   \n",
       "\n",
       "   ratio_of_unique_Headline_trigram  count_of_articleBody_unigram  \\\n",
       "0                               1.0                         446.0   \n",
       "1                               1.0                         379.0   \n",
       "2                               1.0                         703.0   \n",
       "3                               1.0                         320.0   \n",
       "4                               1.0                          89.0   \n",
       "\n",
       "       ...        denies_exist  not_exist  despite_exist  nope_exist  \\\n",
       "0      ...                 0.0        0.0            0.0         0.0   \n",
       "1      ...                 0.0        0.0            0.0         0.0   \n",
       "2      ...                 0.0        0.0            0.0         0.0   \n",
       "3      ...                 0.0        0.0            0.0         0.0   \n",
       "4      ...                 0.0        0.0            0.0         0.0   \n",
       "\n",
       "   doubt_exist  doubts_exist  bogus_exist  debunk_exist  pranks_exist  \\\n",
       "0          0.0           0.0          0.0           0.0           0.0   \n",
       "1          0.0           0.0          0.0           0.0           0.0   \n",
       "2          0.0           0.0          0.0           0.0           0.0   \n",
       "3          0.0           0.0          0.0           0.0           0.0   \n",
       "4          0.0           0.0          0.0           0.0           0.0   \n",
       "\n",
       "   retract_exist  \n",
       "0            0.0  \n",
       "1            0.0  \n",
       "2            0.0  \n",
       "3            0.0  \n",
       "4            0.0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(k_df))\n",
    "k_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6335\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_of_Headline_unigram</th>\n",
       "      <th>count_of_unique_Headline_unigram</th>\n",
       "      <th>ratio_of_unique_Headline_unigram</th>\n",
       "      <th>count_of_Headline_bigram</th>\n",
       "      <th>count_of_unique_Headline_bigram</th>\n",
       "      <th>ratio_of_unique_Headline_bigram</th>\n",
       "      <th>count_of_Headline_trigram</th>\n",
       "      <th>count_of_unique_Headline_trigram</th>\n",
       "      <th>ratio_of_unique_Headline_trigram</th>\n",
       "      <th>count_of_articleBody_unigram</th>\n",
       "      <th>...</th>\n",
       "      <th>denies_exist</th>\n",
       "      <th>not_exist</th>\n",
       "      <th>despite_exist</th>\n",
       "      <th>nope_exist</th>\n",
       "      <th>doubt_exist</th>\n",
       "      <th>doubts_exist</th>\n",
       "      <th>bogus_exist</th>\n",
       "      <th>debunk_exist</th>\n",
       "      <th>pranks_exist</th>\n",
       "      <th>retract_exist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>681.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   count_of_Headline_unigram  count_of_unique_Headline_unigram  \\\n",
       "0                        3.0                               3.0   \n",
       "1                       11.0                              11.0   \n",
       "2                        5.0                               5.0   \n",
       "3                        8.0                               8.0   \n",
       "4                        6.0                               6.0   \n",
       "\n",
       "   ratio_of_unique_Headline_unigram  count_of_Headline_bigram  \\\n",
       "0                               1.0                       2.0   \n",
       "1                               1.0                      10.0   \n",
       "2                               1.0                       4.0   \n",
       "3                               1.0                       7.0   \n",
       "4                               1.0                       5.0   \n",
       "\n",
       "   count_of_unique_Headline_bigram  ratio_of_unique_Headline_bigram  \\\n",
       "0                              2.0                              1.0   \n",
       "1                             10.0                              1.0   \n",
       "2                              4.0                              1.0   \n",
       "3                              7.0                              1.0   \n",
       "4                              5.0                              1.0   \n",
       "\n",
       "   count_of_Headline_trigram  count_of_unique_Headline_trigram  \\\n",
       "0                        1.0                               1.0   \n",
       "1                        9.0                               9.0   \n",
       "2                        3.0                               3.0   \n",
       "3                        6.0                               6.0   \n",
       "4                        4.0                               4.0   \n",
       "\n",
       "   ratio_of_unique_Headline_trigram  count_of_articleBody_unigram  \\\n",
       "0                               1.0                         681.0   \n",
       "1                               1.0                         247.0   \n",
       "2                               1.0                         244.0   \n",
       "3                               1.0                         264.0   \n",
       "4                               1.0                         183.0   \n",
       "\n",
       "       ...        denies_exist  not_exist  despite_exist  nope_exist  \\\n",
       "0      ...                 0.0        0.0            0.0         0.0   \n",
       "1      ...                 0.0        0.0            0.0         0.0   \n",
       "2      ...                 0.0        0.0            0.0         0.0   \n",
       "3      ...                 0.0        0.0            0.0         0.0   \n",
       "4      ...                 0.0        0.0            0.0         0.0   \n",
       "\n",
       "   doubt_exist  doubts_exist  bogus_exist  debunk_exist  pranks_exist  \\\n",
       "0          0.0           0.0          0.0           0.0           0.0   \n",
       "1          0.0           0.0          0.0           0.0           0.0   \n",
       "2          0.0           0.0          0.0           0.0           0.0   \n",
       "3          0.0           0.0          0.0           0.0           0.0   \n",
       "4          0.0           0.0          0.0           0.0           0.0   \n",
       "\n",
       "   retract_exist  \n",
       "0            0.0  \n",
       "1            0.0  \n",
       "2            0.0  \n",
       "3            0.0  \n",
       "4            0.0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(cf_df))\n",
    "cf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_of_Headline_unigram</th>\n",
       "      <th>count_of_unique_Headline_unigram</th>\n",
       "      <th>ratio_of_unique_Headline_unigram</th>\n",
       "      <th>count_of_Headline_bigram</th>\n",
       "      <th>count_of_unique_Headline_bigram</th>\n",
       "      <th>ratio_of_unique_Headline_bigram</th>\n",
       "      <th>count_of_Headline_trigram</th>\n",
       "      <th>count_of_unique_Headline_trigram</th>\n",
       "      <th>ratio_of_unique_Headline_trigram</th>\n",
       "      <th>count_of_articleBody_unigram</th>\n",
       "      <th>...</th>\n",
       "      <th>despite_exist</th>\n",
       "      <th>nope_exist</th>\n",
       "      <th>doubt_exist</th>\n",
       "      <th>doubts_exist</th>\n",
       "      <th>bogus_exist</th>\n",
       "      <th>debunk_exist</th>\n",
       "      <th>pranks_exist</th>\n",
       "      <th>retract_exist</th>\n",
       "      <th>target</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>REAL</td>\n",
       "      <td>Dataset - 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>Dataset - 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>Dataset - 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>Dataset - 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>Dataset - 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   count_of_Headline_unigram  count_of_unique_Headline_unigram  \\\n",
       "0                        7.0                               7.0   \n",
       "1                        9.0                               9.0   \n",
       "2                        2.0                               2.0   \n",
       "3                        7.0                               7.0   \n",
       "4                        4.0                               4.0   \n",
       "\n",
       "   ratio_of_unique_Headline_unigram  count_of_Headline_bigram  \\\n",
       "0                               1.0                       6.0   \n",
       "1                               1.0                       8.0   \n",
       "2                               1.0                       1.0   \n",
       "3                               1.0                       6.0   \n",
       "4                               1.0                       3.0   \n",
       "\n",
       "   count_of_unique_Headline_bigram  ratio_of_unique_Headline_bigram  \\\n",
       "0                              6.0                              1.0   \n",
       "1                              8.0                              1.0   \n",
       "2                              1.0                              1.0   \n",
       "3                              6.0                              1.0   \n",
       "4                              3.0                              1.0   \n",
       "\n",
       "   count_of_Headline_trigram  count_of_unique_Headline_trigram  \\\n",
       "0                        5.0                               5.0   \n",
       "1                        7.0                               7.0   \n",
       "2                        1.0                               1.0   \n",
       "3                        5.0                               5.0   \n",
       "4                        2.0                               2.0   \n",
       "\n",
       "   ratio_of_unique_Headline_trigram  count_of_articleBody_unigram  \\\n",
       "0                               1.0                         312.0   \n",
       "1                               1.0                         158.0   \n",
       "2                               1.0                         159.0   \n",
       "3                               1.0                         119.0   \n",
       "4                               1.0                         173.0   \n",
       "\n",
       "      ...       despite_exist  nope_exist  doubt_exist  doubts_exist  \\\n",
       "0     ...                 0.0         0.0          0.0           0.0   \n",
       "1     ...                 0.0         0.0          0.0           0.0   \n",
       "2     ...                 0.0         0.0          0.0           0.0   \n",
       "3     ...                 0.0         0.0          0.0           0.0   \n",
       "4     ...                 0.0         0.0          0.0           0.0   \n",
       "\n",
       "   bogus_exist  debunk_exist  pranks_exist  retract_exist  target      dataset  \n",
       "0          0.0           0.0           0.0            0.0    REAL  Dataset - 1  \n",
       "1          0.0           0.0           0.0            0.0    FAKE  Dataset - 1  \n",
       "2          0.0           0.0           0.0            0.0    FAKE  Dataset - 1  \n",
       "3          0.0           0.0           0.0            0.0    FAKE  Dataset - 1  \n",
       "4          0.0           0.0           0.0            0.0    FAKE  Dataset - 1  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combined dataframe\n",
    "cf_combined = pd.concat([op_df, k_df, cf_df], ignore_index = True)\n",
    "# Adding Target and Dataset columns\n",
    "cf_combined['target'] = f_combined['target']\n",
    "cf_combined['dataset'] = f_combined['dataset']\n",
    "cf_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "f_combined.to_csv('features_combined.csv', index = False)\n",
    "cf_combined.to_csv('count_features_combined.csv', index = False)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FAKE    10413\n",
       "REAL    10387\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "f_combined[f_combined['dataset'] == 'Dataset - 2']['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FAKE    10413\n",
       "REAL    10387\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_combined[cf_combined['dataset'] == 'Dataset - 2']['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
